{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04f8fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================\n",
      "Step 0: Download and Preprocess\n",
      "===============================\n",
      "\n",
      "Done!\n",
      "\n",
      "=================================\n",
      "Step 1: GNN Dataset & Quick Check\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # read Dataframe \n",
    "import torch\n",
    "from torch_geometric.data import Dataset, Data # for creating graph-based datasets\n",
    "import os # for file and directory operations \n",
    "import numpy as np # for numerical computations with arrays \n",
    "import gseapy as gp # for retrieving pathway information\n",
    "\n",
    "\n",
    "# Creating a Custom Dataset in Pytorch Geometric \n",
    "\n",
    "# -----------------------------------\n",
    "# Step 0: Load and Prepare DataFrames\n",
    "# -----------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*31)\n",
    "print(\"Step 0: Download and Preprocess\")\n",
    "print(\"=\"*31)\n",
    "\n",
    "# Load the full GDSC dataset (FPKM + AUC values for all drugs)\n",
    "# gdsc_dataset = pd.read_csv('/sybig/home/tmu/TUGDA/data/GDSCDA_fpkm_AUC_all_drugs.zip', index_col=0)\n",
    "gdsc_dataset = pd.read_csv('/Users/tm03/Desktop/TUGDA_1/data/GDSCDA_fpkm_AUC_all_drugs.zip', index_col=0)\n",
    "# Extract gene and drug columns:\n",
    "# - First 1780 columns correspond to gene expression data\n",
    "# - Remaining columns represent drug AUC values\n",
    "gene_list = gdsc_dataset.columns[0:1780]\n",
    "drug_list = gdsc_dataset.columns[1780:] \n",
    "\n",
    "# Retrieve KEGG pathways using gseapy\n",
    "kegg_gmt = gp.parser.get_library('KEGG_2021_Human', organism='Human', min_size=3, max_size=2000)\n",
    "pathway_list = list(kegg_gmt.keys())\n",
    "\n",
    "# Gene Expression Data (FPKM values)\n",
    "expression_data = gdsc_dataset.iloc[:, :1780]\n",
    "\n",
    "# Response Data: Combine log_IC50 values from 3-fold cross-validation test sets\n",
    "# response_1 = pd.read_csv(\"/sybig/home/tmu/TUGDA/data/cl_y_test_o_k1.csv\", index_col=0)\n",
    "# response_2 = pd.read_csv(\"/sybig/home/tmu/TUGDA/data/cl_y_test_o_k2.csv\", index_col=0)\n",
    "# response_3 = pd.read_csv(\"/sybig/home/tmu/TUGDA/data/cl_y_test_o_k3.csv\", index_col=0)\n",
    "\n",
    "response_1 = pd.read_csv(\"/Users/tm03/Desktop/TUGDA_1/data/cl_y_test_o_k1.csv\", index_col=0)\n",
    "response_2 = pd.read_csv(\"/Users/tm03/Desktop/TUGDA_1/data/cl_y_test_o_k2.csv\", index_col=0)\n",
    "response_3 = pd.read_csv(\"/Users/tm03/Desktop/TUGDA_1/data/cl_y_test_o_k3.csv\", index_col=0)\n",
    "response_data = pd.concat([response_1, response_2, response_3], axis=0, ignore_index=False)\n",
    "\n",
    "# Sort both datasets by index to ensure alignment\n",
    "expression_data = expression_data.sort_index()\n",
    "response_data = response_data.sort_index()\n",
    "\n",
    "# Remove duplicate indices (keep first occurrence) to avoid conflicts during merging\n",
    "expression_data = expression_data[~expression_data.index.duplicated(keep='first')]\n",
    "labels_df = response_data[~response_data.index.duplicated(keep='first')] \n",
    "\n",
    "print(\"\\n\" + \"Done!\")\n",
    "\n",
    "###################\n",
    "### GNN Dataset ###\n",
    "###################\n",
    "\n",
    "print(\"\\n\" + \"=\"*33)\n",
    "print(\"Step 1: GNN Dataset & Quick Check\")\n",
    "print(\"=\"*33)\n",
    "\n",
    "class DrugNetworkDataset(Dataset):\n",
    "    def __init__(self, root, drug_list, gene_list, pathway_list, labels_df, expression_data, transform=None, pre_transform=None):\n",
    "\n",
    "        \"\"\"\n",
    "        A custom PyTorch Geometric Dataset for drug-cell line interaction graphs.\n",
    "\n",
    "        Parameters:\n",
    "            - root = Where the datase4t should be stored. This folder is split \n",
    "            - into raw_dir (downloaded datset) and processed_dir (processed data)\n",
    "\n",
    "            - drug_list: List of drugs (tasks) (200)\n",
    "            - gene_list: Lisz of genes sample (1780)\n",
    "            - pathway_list: List of pathways from KEGG \n",
    "            - labels_df: response data (log_IC50)\n",
    "            - expression_data: Gene expression values (preprocessed according to Mourragui et al. (2020): library-size using TMM, log-transformed, gene-level-mean-centering and standardization)\n",
    "        \"\"\"\n",
    "\n",
    "        # Define all files that the dataset needs\n",
    "        self.drug_list = drug_list\n",
    "        self.gene_list = gene_list\n",
    "        self.pathway_list = pathway_list\n",
    "        self.labels_df = labels_df\n",
    "        self.expression_data = expression_data\n",
    "\n",
    "        # Get all combination of Drug + Cell Line\n",
    "        self.samples = [\n",
    "            (drug, cell_line) \n",
    "            for drug in self.drug_list \n",
    "            for cell_line in self.labels_df.index\n",
    "        ]\n",
    "\n",
    "        # Define custom raw_dir\n",
    "        self.custom_raw_dir = os.path.join(root, 'drug_matrices_csv')\n",
    "\n",
    "        super(DrugNetworkDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\" If these files exist in raw_dir, the download is not triggered \"\"\"\n",
    "        return [f\"{drug}_matrix.csv\" for drug in self.drug_list]\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return self.custom_raw_dir\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" If these files exist in processed_dir, processing is skipped \"\"\"\n",
    "        return ['placeholder.pt'] # not implemented \n",
    "        #  return [f'data_{i}.pt' for i in range(len(self.samples))]\n",
    "\n",
    "    def download(self):\n",
    "        pass \n",
    "\n",
    "    def _load_adjacency_matrix(self, drug):\n",
    "        \"\"\" Loads the adjacency matrix for every drug \"\"\"\n",
    "        csv_path = os.path.join(self.raw_dir, f\"{drug}_matrix.csv\")\n",
    "        df = pd.read_csv(csv_path, index_col=0)\n",
    "        return df\n",
    "\n",
    "    def _get_node_features(self, nodes, cell_line):\n",
    "        x = []\n",
    "        for node in nodes:\n",
    "            if node in self.gene_list:\n",
    "                 # If the node is a gene, get its expression value for the given cell line and type [expr, is_gene, is_pathway]\n",
    "                expr_value = self.expression_data.loc[cell_line, node]\n",
    "                x.append([float(expr_value), 1.0, 0.0])  # [expr, is_gene, is_pathway]\n",
    "            elif node in self.pathway_list:\n",
    "                # If the node is a pathway, use a default feature value of 0.0\n",
    "                x.append([0.0, 0.0, 1.0])  # [expr_dummy, is_gene, is_pathway]\n",
    "            else:\n",
    "                # Unknown node\n",
    "                x.append([0.0, 0.0, 0.0])  # [expr_dummy, is_gene, is_pathway]\n",
    "        return torch.tensor(x, dtype=torch.float)\n",
    "\n",
    "        ''' Code for just Gene expression value: \n",
    "        x = []\n",
    "        for node in nodes:\n",
    "             # If the node is a gene, get its expression value for the given cell line\n",
    "            if node in self.gene_list:\n",
    "                expr_value = self.expression_data.loc[cell_line, node]\n",
    "                x.append([float(expr_value)]) # Append as a single-element list \n",
    "            elif node in self.pathway_list:\n",
    "                # If the node is a pathway, use a default feature value of 0.0\n",
    "                x.append([0.0])\n",
    "            else:\n",
    "                x.append([0.0])\n",
    "        return torch.tensor(x, dtype=torch.float)\n",
    "        ''' \n",
    "    \n",
    "    # Qucik check fuction for debugging\n",
    "    def get_node_name_by_index(self, idx, node_index):\n",
    "        \"\"\" Returns the name of the node at the specified index for the given sample \"\"\"\n",
    "        drug, cell_line = self.samples[idx]\n",
    "        \n",
    "        adj_df = self._load_adjacency_matrix(drug)\n",
    "        nodes = adj_df.columns.tolist()\n",
    "        \n",
    "        if node_index < len(nodes):\n",
    "            return nodes[node_index]\n",
    "        else:\n",
    "            raise IndexError(f\"Node index {node_index} out of range for this graph.\")\n",
    "\n",
    "    def len(self):\n",
    "        \"\"\" \n",
    "        Returns the total number of samples (drug-cell line combinations)\n",
    "        useful for classes such as datasets for machine learning so that they are compatible with len() and for loops \n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"\n",
    "        In standard PyG datasets, get() loads preprocessed data saved via process(); \n",
    "        here the preprocessing step is skipped and construct each drugâ€“cell line graph directly in get(), \n",
    "        as preprocessing wouldn't reduce computation time\n",
    "        \"\"\"\n",
    "        drug, cell_line = self.samples[idx]\n",
    "\n",
    "        # Load adjacency matric for each drug \n",
    "        adj_df = self._load_adjacency_matrix(drug)\n",
    "        nodes = adj_df.columns.tolist()\n",
    "        adj_matrix = adj_df.values\n",
    "        # Build edge_index in COO format\n",
    "        edge_index = torch.tensor(np.array(np.nonzero(adj_matrix)), dtype=torch.long)\n",
    "        # Get node_features\n",
    "        x = self._get_node_features(nodes, cell_line)\n",
    "        # Get label info (log_IC50 value for each drug-cell line combination)\n",
    "        # y = torch.tensor([self.labels_df.loc[cell_line, drug]], dtype=torch.float)\n",
    "\n",
    "        label_value = self.labels_df.loc[cell_line, drug]\n",
    "        if pd.isna(label_value):\n",
    "            return self.__getitem__((idx + 1) % len(self))  # nÃ¤chstes Sample probieren\n",
    "        \n",
    "        y = torch.tensor([float(label_value)], dtype=torch.float)\n",
    "\n",
    "        # Create data object\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, drug=drug, cell_line=cell_line)\n",
    "\n",
    "        # Attach node names for debugging purposes\n",
    "        data.nodes = nodes\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def process(self):\n",
    "        pass # Skip right now, can be implemented to store the output files in your\n",
    "        '''\n",
    "        for i in range(len(self.samples)):\n",
    "            data = self.get(i)\n",
    "            torch.save(data, os.path.join(self.processed_dir, f'data_{i}.pt'))\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae297e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, TopKPooling, GCNConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "class GNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, heads, ratio):\n",
    "        super().__init__()\n",
    "        # self.conv = GATConv(in_channels, out_channels, heads=heads, dropout=0.6)\n",
    "        # self.transform = nn.Linear(out_channels * heads, out_channels)\n",
    "        self.conv = GCNConv(in_channels, out_channels)  # Kein heads-Parameter\n",
    "        self.transform = nn.Linear(out_channels, out_channels)  # Ohne heads * out_channels\n",
    "        self.pool = TopKPooling(out_channels, ratio=ratio)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv(x, edge_index)\n",
    "        x = F.relu(self.transform(x))\n",
    "        x = self.bn(x)\n",
    "        x, edge_index, _, batch, _, _ = self.pool(x, edge_index, None, batch)\n",
    "        return x, edge_index, batch\n",
    "\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(self, feature_size=1, embedding_size=32, output_dim=16):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "\n",
    "        self.block1 = GNNBlock(in_channels=feature_size, out_channels=embedding_size, heads=3, ratio=0.8)\n",
    "        self.block2 = GNNBlock(in_channels=embedding_size, out_channels=embedding_size, heads=3, ratio=0.5)\n",
    "        self.block3 = GNNBlock(in_channels=embedding_size, out_channels=embedding_size, heads=3, ratio=0.2)\n",
    "\n",
    "        # Final projection\n",
    "        self.linear1 = nn.Linear(embedding_size * 2, 128)\n",
    "        self.linear2 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # Block 1\n",
    "        x, edge_index, batch = self.block1(x, edge_index, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        # Block 2\n",
    "        x, edge_index, batch = self.block2(x, edge_index, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        # Block 3\n",
    "        x, edge_index, batch = self.block3(x, edge_index, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        # Combine pooled outputs\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        # Final projection\n",
    "        x = self.linear1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)  # Optional: dropout p=0.8 â†’ 0.5\n",
    "        graph_embedding = self.linear2(x)\n",
    "\n",
    "        return graph_embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fc59dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Echtes Embedding Shape: torch.Size([1, 256])\n",
      "tensor([[ 4.8114e-03, -3.0771e-02, -2.0618e-02,  1.1778e-03, -3.1502e-03,\n",
      "          4.1565e-02,  3.6314e-02, -3.2110e-02,  2.9935e-02,  4.1352e-02,\n",
      "         -3.3374e-02, -3.5360e-02,  4.2497e-02,  2.8199e-02,  2.7739e-02,\n",
      "         -3.4205e-02,  2.1935e-02,  3.2177e-02, -3.1567e-03, -1.9492e-02,\n",
      "          1.8535e-02,  5.3408e-03, -1.8785e-02,  8.4074e-03, -2.4234e-02,\n",
      "         -2.9076e-02, -2.4892e-02, -2.5499e-02, -2.2481e-02,  5.0862e-02,\n",
      "         -4.7569e-02, -1.3031e-02, -1.7625e-02,  3.3975e-02, -7.3230e-03,\n",
      "          3.5741e-02,  4.4565e-02, -4.6033e-02, -3.7713e-02,  4.9750e-02,\n",
      "         -4.0473e-02,  1.9499e-02, -5.4038e-02,  1.5889e-04,  3.6636e-02,\n",
      "         -2.4025e-02,  3.3086e-02,  6.4988e-03, -3.4207e-02,  1.7666e-02,\n",
      "         -2.0782e-03, -3.1399e-02,  1.6178e-02, -2.8136e-02,  1.9356e-02,\n",
      "          3.5235e-02,  2.6857e-02,  6.6925e-03, -3.2557e-03,  1.5801e-02,\n",
      "          2.1448e-02,  3.4143e-02, -3.1542e-02, -1.1062e-02, -3.6221e-02,\n",
      "         -1.8917e-02, -5.5600e-02, -3.4989e-02,  3.7929e-02,  3.6388e-02,\n",
      "         -4.0392e-02,  5.0050e-02,  2.5908e-02,  3.4293e-02, -3.0390e-02,\n",
      "          1.7821e-02, -4.0938e-02, -1.4967e-02, -1.6435e-02,  4.0489e-02,\n",
      "         -3.2643e-02,  4.0735e-02, -3.3435e-02,  1.1682e-02,  1.0871e-02,\n",
      "          3.7611e-02,  1.1618e-02,  4.1745e-02, -2.6385e-02, -8.8640e-03,\n",
      "          1.5160e-02,  1.9423e-02,  2.0731e-02,  3.4492e-02,  2.2315e-02,\n",
      "         -5.0320e-02, -3.3658e-02,  4.9977e-02, -2.1172e-02, -3.0620e-02,\n",
      "         -2.8150e-02, -1.4818e-02, -1.5432e-02,  1.5488e-03, -2.5735e-03,\n",
      "          1.7740e-02,  2.7944e-02,  1.8462e-02, -4.0153e-02, -1.5109e-02,\n",
      "         -2.8913e-02,  1.4838e-02,  4.4942e-03,  1.4106e-03, -1.9144e-02,\n",
      "          3.1105e-02, -1.5330e-02, -2.1751e-02, -2.8425e-03, -5.5202e-02,\n",
      "          1.6519e-02, -3.6875e-03,  4.5932e-02, -4.8309e-02, -3.7336e-02,\n",
      "          3.3957e-02,  4.4549e-02, -9.1345e-04,  3.6731e-02,  4.9228e-02,\n",
      "          4.4118e-03, -4.9493e-02,  9.3576e-03,  3.1740e-02,  4.7382e-02,\n",
      "         -1.0536e-02, -2.6973e-02,  1.9885e-02, -9.1411e-03,  2.8644e-03,\n",
      "          1.8944e-02, -2.4210e-02, -6.0236e-03, -9.5400e-03,  1.3843e-02,\n",
      "         -1.0251e-03, -2.2174e-02,  3.3900e-02,  2.3147e-05,  4.5196e-02,\n",
      "          3.1250e-02, -3.9241e-03,  2.8916e-02, -2.9231e-02, -1.7774e-02,\n",
      "         -2.9093e-02, -1.0480e-02, -5.0222e-02,  2.7456e-02, -6.8448e-03,\n",
      "          1.9232e-02, -9.0301e-03, -1.3248e-02,  4.1605e-02,  5.8370e-04,\n",
      "          7.2349e-03,  3.5225e-02, -4.5841e-03,  6.2140e-03,  1.0354e-02,\n",
      "         -1.4459e-02,  1.6478e-02,  4.3163e-02, -4.6178e-02,  1.3397e-02,\n",
      "         -1.9137e-02,  3.0558e-02, -9.2384e-03, -4.0960e-02, -3.6713e-02,\n",
      "          1.2156e-02, -9.4659e-03, -3.6177e-02,  3.1378e-02,  4.1523e-02,\n",
      "         -1.2514e-02,  1.2606e-02,  6.0112e-02,  3.6082e-02, -1.3543e-02,\n",
      "         -2.0485e-02, -3.3642e-02,  3.8680e-02, -2.5960e-02,  2.2177e-03,\n",
      "         -3.6209e-02, -2.5922e-03,  4.2720e-03,  3.2007e-02, -1.8892e-02,\n",
      "          4.2543e-02, -4.1225e-02,  4.0162e-02,  1.1016e-02,  1.9192e-02,\n",
      "         -2.0339e-02, -8.7164e-03, -7.0203e-04, -4.5326e-02, -3.6964e-02,\n",
      "          5.6847e-02, -3.9709e-03,  1.9295e-02,  4.2274e-04,  1.2151e-02,\n",
      "         -4.6415e-02,  1.5614e-02, -4.1910e-03,  2.4148e-02,  2.3419e-02,\n",
      "         -3.6317e-02, -2.4007e-02, -4.4146e-03, -2.7267e-03,  1.5090e-02,\n",
      "         -2.1359e-02,  4.7200e-02, -1.7084e-02,  3.5378e-03,  5.1996e-03,\n",
      "         -1.2720e-02,  2.3970e-02,  2.8341e-02,  3.0057e-02, -4.3128e-02,\n",
      "          3.6290e-02, -1.7826e-02,  2.6574e-02,  2.2942e-02, -7.5881e-04,\n",
      "         -1.3613e-02,  4.9991e-03, -1.6091e-02, -4.7879e-02, -1.5465e-02,\n",
      "         -3.6139e-02,  4.6818e-02,  2.2417e-02, -2.2456e-02, -3.7634e-02,\n",
      "         -5.4935e-03, -2.9074e-02, -1.5520e-03, -1.1353e-02, -1.7956e-02,\n",
      "         -4.6070e-02]])\n"
     ]
    }
   ],
   "source": [
    "# Hole einen echten Datensatz\n",
    "data = dataset[0]  # Dataset[Index] gibt ein Data-Objekt zurÃ¼ck\n",
    "\n",
    "encoder = GNNEncoder(feature_size=3, embedding_size=512, output_dim=256)\n",
    "\n",
    "# Encoder aufrufen\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    embedding = encoder(data)\n",
    "\n",
    "print(\"Echtes Embedding Shape:\", embedding.shape)\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2d37e8",
   "metadata": {},
   "source": [
    "# TUGDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7feb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of drugs to be trained and predicted\n",
    "folder = 'data/'\n",
    "drug_list = pd.read_csv('{}/cl_y_test_o_k1.csv'.format(folder), index_col=0 )\n",
    "drug_list = drug_list.columns\n",
    "\n",
    "#3-fold training and test data;\n",
    "train_data_report = {}\n",
    "test_data_report = {}\n",
    "\n",
    "for k in range(1,4):\n",
    "    train_data_report['x_k_fold{}'.format(k)] = pd.read_csv('{}/cl_x_train_o_k{}.csv'.format(folder, k), index_col=0)\n",
    "    train_data_report['y_k_fold{}'.format(k)] = pd.read_csv('{}/cl_y_train_o_k{}.csv'.format(folder, k), index_col=0)\n",
    "    \n",
    "    test_data_report['x_k_fold{}'.format(k)] = pd.read_csv('{}/cl_x_test_o_k{}.csv'.format(folder, k), index_col=0)\n",
    "    test_data_report['y_k_fold{}'.format(k)] = pd.read_csv('{}/cl_y_test_o_k{}.csv'.format(folder, k), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68c9a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40fc6fd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callback\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mMetricsCallback\u001b[39;00m(Callback):\n\u001b[32m      4\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"PyTorch Lightning metric callback.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/pytorch_lightning/__init__.py:56\u001b[39m\n\u001b[32m     53\u001b[39m     sys.stdout.write(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mPartial import of `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# pragma: no-cover\u001b[39;00m\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# We are not importing the rest of the lightning during the build process, as it may not be compiled yet\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LightningDataModule, LightningModule\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstep_result\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainResult, EvalResult\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callback\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/pytorch_lightning/core/__init__.py:3\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatamodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LightningDataModule\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlightning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LightningModule\n\u001b[32m      5\u001b[39m __all__ = [\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mLightningDataModule\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mLightningModule\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m ]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# __call__ = __all__\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/pytorch_lightning/core/lightning.py:36\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelHooks\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelSummary\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALLOWED_CONFIG_TYPES, PRIMITIVE_TYPES, ModelIO\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moverrides\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_parallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LightningDistributedDataParallel\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rank_zero_warn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _logger \u001b[38;5;28;01mas\u001b[39;00m log\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rank_zero_warn, AttributeDict\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud_io\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load \u001b[38;5;28;01mas\u001b[39;00m pl_load\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutilities\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud_io\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gfile, cloud_open\n\u001b[32m     30\u001b[39m PRIMITIVE_TYPES = (\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/pytorch_lightning/utilities/cloud_io.py:33\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# we want this for tf.io.gfile, which if tf is installed gives full tf,\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# otherwise gives a pruned down version which works for some file backends but\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# not all\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m gfile = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m.gfile\n\u001b[32m     35\u001b[39m pathlike = Union[Path, \u001b[38;5;28mstr\u001b[39m]\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# older version of tensorboard had buggy gfile compatibility layers\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# only support remote cloud paths if newer\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/tensorboard/lazy.py:68\u001b[39m, in \u001b[36mlazy_load.<locals>.wrapper.<locals>.LazyModule.__getattr__\u001b[39m\u001b[34m(self, attr_name)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr_name):\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mload_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m, attr_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/tensorboard/lazy.py:100\u001b[39m, in \u001b[36m_memoize.<locals>.wrapper\u001b[39m\u001b[34m(arg)\u001b[39m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[32m     99\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m cache.get(arg, nothing) \u001b[38;5;129;01mis\u001b[39;00m nothing:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m             cache[arg] = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cache[arg]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/tensorboard/lazy.py:53\u001b[39m, in \u001b[36mlazy_load.<locals>.wrapper.<locals>.load_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     51\u001b[39m load_once.loading = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     module = \u001b[43mload_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     55\u001b[39m     load_once.loading = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/tensorboard/compat/__init__.py:55\u001b[39m, in \u001b[36mtf\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     54\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensorflow_stub\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensorflow_stub\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/tensorboard/compat/tensorflow_stub/__init__.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_pb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevent_pb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_pb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/tensorboard/compat/proto/config_pb2.py:16\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[32m     13\u001b[39m _sym_db = _symbol_database.Default()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cost_graph_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_cost__graph__pb2\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m graph_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_graph__pb2\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m step_stats_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_step__stats__pb2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/tensorboard/compat/proto/cost_graph_pb2.py:16\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[32m     13\u001b[39m _sym_db = _symbol_database.Default()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_shape_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_types__pb2\n\u001b[32m     20\u001b[39m DESCRIPTOR = _descriptor.FileDescriptor(\n\u001b[32m     21\u001b[39m   name=\u001b[33m'\u001b[39m\u001b[33mtensorboard/compat/proto/cost_graph.proto\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     22\u001b[39m   package=\u001b[33m'\u001b[39m\u001b[33mtensorboard\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m   ,\n\u001b[32m     27\u001b[39m   dependencies=[tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2.DESCRIPTOR,tensorboard_dot_compat_dot_proto_dot_types__pb2.DESCRIPTOR,])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/tensorboard/compat/proto/tensor_shape_pb2.py:36\u001b[39m\n\u001b[32m     13\u001b[39m _sym_db = _symbol_database.Default()\n\u001b[32m     18\u001b[39m DESCRIPTOR = _descriptor.FileDescriptor(\n\u001b[32m     19\u001b[39m   name=\u001b[33m'\u001b[39m\u001b[33mtensorboard/compat/proto/tensor_shape.proto\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     20\u001b[39m   package=\u001b[33m'\u001b[39m\u001b[33mtensorboard\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m   serialized_pb=_b(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m+tensorboard/compat/proto/tensor_shape.proto\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[33mtensorboard\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x10\u001b[39;00m\u001b[33mTensorShapeProto\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x64\u001b[39;00m\u001b[33mim\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x32\u001b[39;00m\u001b[33m!.tensorboard.TensorShapeProto.Dim\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x14\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[33munknown_rank\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x08\u001b[39;00m\u001b[38;5;130;01m\\x1a\u001b[39;00m\u001b[33m!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x44\u001b[39;00m\u001b[33mim\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[33msize\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[33mname\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mB\u001b[39m\u001b[38;5;130;01m\\x87\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[33morg.tensorflow.frameworkB\u001b[39m\u001b[38;5;130;01m\\x11\u001b[39;00m\u001b[33mTensorShapeProtosP\u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[33mZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\u001b[39m\u001b[38;5;130;01m\\xf8\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\x62\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[33mproto3\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     24\u001b[39m )\n\u001b[32m     29\u001b[39m _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n\u001b[32m     30\u001b[39m   name=\u001b[33m'\u001b[39m\u001b[33mDim\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     31\u001b[39m   full_name=\u001b[33m'\u001b[39m\u001b[33mtensorboard.TensorShapeProto.Dim\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     32\u001b[39m   filename=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     33\u001b[39m   file=DESCRIPTOR,\n\u001b[32m     34\u001b[39m   containing_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     35\u001b[39m   fields=[\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[43m_descriptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFieldDescriptor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msize\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtensorboard.TensorShapeProto.Dim.size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpp_type\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m      \u001b[49m\u001b[43mhas_default_value\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessage_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menum_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontaining_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m      \u001b[49m\u001b[43mis_extension\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_scope\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDESCRIPTOR\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     43\u001b[39m     _descriptor.FieldDescriptor(\n\u001b[32m     44\u001b[39m       name=\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m, full_name=\u001b[33m'\u001b[39m\u001b[33mtensorboard.TensorShapeProto.Dim.name\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[32m1\u001b[39m,\n\u001b[32m     45\u001b[39m       number=\u001b[32m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[32m9\u001b[39m, cpp_type=\u001b[32m9\u001b[39m, label=\u001b[32m1\u001b[39m,\n\u001b[32m     46\u001b[39m       has_default_value=\u001b[38;5;28;01mFalse\u001b[39;00m, default_value=_b(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).decode(\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     47\u001b[39m       message_type=\u001b[38;5;28;01mNone\u001b[39;00m, enum_type=\u001b[38;5;28;01mNone\u001b[39;00m, containing_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     48\u001b[39m       is_extension=\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     49\u001b[39m       serialized_options=\u001b[38;5;28;01mNone\u001b[39;00m, file=DESCRIPTOR),\n\u001b[32m     50\u001b[39m   ],\n\u001b[32m     51\u001b[39m   extensions=[\n\u001b[32m     52\u001b[39m   ],\n\u001b[32m     53\u001b[39m   nested_types=[],\n\u001b[32m     54\u001b[39m   enum_types=[\n\u001b[32m     55\u001b[39m   ],\n\u001b[32m     56\u001b[39m   serialized_options=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     57\u001b[39m   is_extendable=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     58\u001b[39m   syntax=\u001b[33m'\u001b[39m\u001b[33mproto3\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     59\u001b[39m   extension_ranges=[],\n\u001b[32m     60\u001b[39m   oneofs=[\n\u001b[32m     61\u001b[39m   ],\n\u001b[32m     62\u001b[39m   serialized_start=\u001b[32m150\u001b[39m,\n\u001b[32m     63\u001b[39m   serialized_end=\u001b[32m183\u001b[39m,\n\u001b[32m     64\u001b[39m )\n\u001b[32m     66\u001b[39m _TENSORSHAPEPROTO = _descriptor.Descriptor(\n\u001b[32m     67\u001b[39m   name=\u001b[33m'\u001b[39m\u001b[33mTensorShapeProto\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     68\u001b[39m   full_name=\u001b[33m'\u001b[39m\u001b[33mtensorboard.TensorShapeProto\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m   serialized_end=\u001b[32m183\u001b[39m,\n\u001b[32m    101\u001b[39m )\n\u001b[32m    103\u001b[39m _TENSORSHAPEPROTO_DIM.containing_type = _TENSORSHAPEPROTO\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/google/protobuf/descriptor.py:621\u001b[39m, in \u001b[36mFieldDescriptor.__new__\u001b[39m\u001b[34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, full_name, index, number, \u001b[38;5;28mtype\u001b[39m, cpp_type, label,\n\u001b[32m    616\u001b[39m             default_value, message_type, enum_type, containing_type,\n\u001b[32m    617\u001b[39m             is_extension, extension_scope, options=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    618\u001b[39m             serialized_options=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    619\u001b[39m             has_default_value=\u001b[38;5;28;01mTrue\u001b[39;00m, containing_oneof=\u001b[38;5;28;01mNone\u001b[39;00m, json_name=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    620\u001b[39m             file=\u001b[38;5;28;01mNone\u001b[39;00m, create_key=\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m   \u001b[43m_message\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_CheckCalledFromGeneratedFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m is_extension:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _message.default_pool.FindExtensionByName(full_name)\n",
      "\u001b[31mTypeError\u001b[39m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Callback\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    \"\"\"PyTorch Lightning metric callback.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metrics = []\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        self.metrics.append(trainer.callback_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78954dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "class tugda_mtl(pl.LightningModule):\n",
    "    def __init__(self, params, drug_list):\n",
    "        super(tugda_mtl, self).__init__()\n",
    "        \n",
    "        # Hyperparameter\n",
    "        self.learning_rate = params['lr']\n",
    "        self.mu = params['mu']           # L1 regularization\n",
    "        self.lambda_ = params['lambda_'] # L2 regularization\n",
    "        self.gamma = params['gamma']     # Autoencoder loss weight\n",
    "        self.passes = params['passes']   # MC-Dropout simulations\n",
    "        self.drug_list = drug_list\n",
    "        self.num_tasks = len(drug_list)\n",
    "        \n",
    "        # Encoder laden\n",
    "        feature_size = 3  # expr_value, is_gene, is_pathway\n",
    "        embedding_size = params.get('hidden_units_1', 512)\n",
    "        output_dim = params.get('latent_space', 256)\n",
    "        \n",
    "        self.gnn_encoder = GNNEncoder(feature_size=feature_size,\n",
    "                                      embedding_size=embedding_size,\n",
    "                                      output_dim=output_dim)\n",
    "\n",
    "        # Task-specific Head (S-Matrix analog)\n",
    "        self.S = nn.Linear(output_dim, self.num_tasks)\n",
    "\n",
    "        # Decoder (Autoencoder Loss)\n",
    "        self.A = nn.Sequential(\n",
    "            nn.Linear(self.num_tasks, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Uncertainty Tracking\n",
    "        self.log_vars = torch.zeros(self.num_tasks, requires_grad=True, device=self.device)\n",
    "\n",
    "    def forward(self, data):\n",
    "        graph_emb = self.gnn_encoder(data)\n",
    "        preds = self.S(graph_emb)\n",
    "        rec_emb = self.A(preds)\n",
    "        return preds, graph_emb, rec_emb\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params = list(self.parameters()) + [self.log_vars]\n",
    "        optimizer = torch.optim.Adagrad(params, lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def _mse_ignore_nan(self, preds, labels, reduction='mean'):\n",
    "        mse_loss = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "        # Sorge dafÃ¼r, dass preds und labels 2D sind\n",
    "        if preds.dim() == 1:\n",
    "            preds = preds.unsqueeze(1)  # [batch_size] -> [batch_size, 1]\n",
    "        if labels.dim() == 1:\n",
    "            labels = labels.unsqueeze(1)  # [batch_size] -> [batch_size, 1]\n",
    "\n",
    "        per_task_loss = torch.zeros(labels.shape[1], device=self.device)\n",
    "\n",
    "        for k in range(labels.shape[1]):\n",
    "            precision = torch.exp(-self.log_vars[k])\n",
    "            mask = ~torch.isnan(labels[:, k])\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            diff = mse_loss(preds[mask, k], labels[mask, k])\n",
    "            per_task_loss[k] = torch.mean(precision * diff) + self.log_vars[k]\n",
    "\n",
    "        if reduction == 'mean':\n",
    "            return torch.mean(per_task_loss[~torch.isnan(per_task_loss)]), per_task_loss\n",
    "        elif reduction == 'none':\n",
    "            return per_task_loss\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        data = train_batch\n",
    "\n",
    "        preds_simulation = torch.zeros(data.y.shape[0], self.num_tasks, self.passes, device=self.device)\n",
    "        for sim in range(self.passes):\n",
    "            pred, h, h_hat = self(data)\n",
    "            preds_simulation[:, :, sim] = pred\n",
    "\n",
    "        preds_mean = preds_simulation.mean(dim=2)  # [batch_size, num_tasks]\n",
    "\n",
    "        # Stelle sicher, dass y 2D ist\n",
    "        if data.y.dim() == 1:\n",
    "            data.y = data.y.unsqueeze(1)  # [batch_size] -> [batch_size, 1]\n",
    "\n",
    "        # Loss Berechnungen\n",
    "        local_loss, task_loss = self._mse_ignore_nan(preds_mean, data.y)\n",
    "        recon_loss = self.gamma * torch.nn.MSELoss()(h, h_hat)\n",
    "\n",
    "        # Berechne a: muss Shape [num_tasks] haben\n",
    "        var_preds = preds_simulation.var(dim=2).mean(dim=0)  # [num_tasks]\n",
    "\n",
    "        # Sicherstellen, dass A richtig skaliert ist\n",
    "        weight_sum = torch.abs(self.A[0].weight).sum(dim=1)  # [out_features] â†’ muss [num_tasks] sein!\n",
    "\n",
    "        # ðŸš¨ Falls A nicht die richtige Form hat (z. B. bei num_tasks=1), fixe sie manuell:\n",
    "        if weight_sum.shape[0] != self.num_tasks:\n",
    "            weight_sum = weight_sum.view(self.num_tasks)\n",
    "\n",
    "        a = 1 + (var_preds + weight_sum)  # [num_tasks]\n",
    "\n",
    "        # Validierungsmaske\n",
    "        valid_mask = ~torch.isnan(task_loss)  # [num_tasks]\n",
    "\n",
    "        # PrÃ¼fung: Shapes mÃ¼ssen Ã¼bereinstimmen\n",
    "        assert a.shape == task_loss.shape, f\"a.shape {a.shape} != task_loss.shape {task_loss.shape}\"\n",
    "\n",
    "        print(\"preds_mean:\", preds_mean.shape)\n",
    "        print(\"data.y:\", data.y.shape)\n",
    "        print(\"var_preds:\", var_preds.shape)\n",
    "        print(\"weight_sum:\", weight_sum.shape)\n",
    "        print(\"a:\", a.shape)\n",
    "        print(\"task_loss:\", task_loss.shape)\n",
    "\n",
    "        weighted_loss = (a[valid_mask] * task_loss[valid_mask]).sum()\n",
    "\n",
    "        l1_S = self.mu * self.S.weight.norm(1)\n",
    "        l2_L = self.lambda_ * (\n",
    "            self.gnn_encoder.linear1.weight.norm(2) +\n",
    "            self.gnn_encoder.linear2.weight.norm(2)\n",
    "        )\n",
    "\n",
    "        total_loss = weighted_loss + recon_loss + l1_S + l2_L\n",
    "        self.log(\"train_loss\", total_loss)\n",
    "\n",
    "        return {'loss': total_loss}\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        data = test_batch\n",
    "\n",
    "        # MC Dropout aktivieren\n",
    "        self.gnn_encoder.train()\n",
    "        self.S.train()\n",
    "        self.A.train()\n",
    "\n",
    "        preds_simulation = torch.zeros(\n",
    "            data.y.shape[0], \n",
    "            self.num_tasks, \n",
    "            self.passes, \n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        for sim in range(self.passes):\n",
    "            with torch.no_grad():\n",
    "                pred, _, _ = self(data)\n",
    "                preds_simulation[:, :, sim] = pred\n",
    "\n",
    "        preds_mean = preds_simulation.mean(dim=2)  # Shape: [batch_size, num_tasks]\n",
    "\n",
    "        # Hole den Index des aktuellen Drugs fÃ¼r jede Probe im Batch\n",
    "        drug_indices = torch.tensor(\n",
    "            [self.drug_list.index(drug) for drug in data.drug], \n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        # WÃ¤hle nur die Vorhersage des zugehÃ¶rigen Drugs aus\n",
    "        preds_task_specific = preds_mean[torch.arange(preds_mean.size(0)), drug_indices]  # Shape: [batch_size]\n",
    "        \n",
    "        # Labels extrahieren\n",
    "        labels = data.y.squeeze()  # Shape: [batch_size]\n",
    "\n",
    "        # Berechne MSE pro Sample\n",
    "        per_sample_loss = F.mse_loss(preds_task_specific, labels, reduction='none')  # Shape: [batch_size]\n",
    "\n",
    "        # Erstelle Tensor zur Zuordnung: sample -> task\n",
    "        task_ids = drug_indices  # Shape: [batch_size]\n",
    "\n",
    "        # Initialisiere leeren Tensor fÃ¼r Task-spezifische Verluste\n",
    "        task_losses = torch.zeros(self.num_tasks, device=self.device)\n",
    "        counts = torch.zeros(self.num_tasks, device=self.device)\n",
    "\n",
    "        # Aggregiere Loss pro Task\n",
    "        for i in range(self.num_tasks):\n",
    "            mask = (task_ids == i)\n",
    "            if mask.any():\n",
    "                task_losses[i] = per_sample_loss[mask].mean()\n",
    "                counts[i] = mask.sum()\n",
    "            else:\n",
    "                task_losses[i] = float('nan')\n",
    "\n",
    "        return {\n",
    "            'test_preds': preds_mean.cpu().numpy(),\n",
    "            'test_task_losses_per_class': task_losses.cpu().numpy(),\n",
    "            'test_task_counts': counts.cpu().numpy()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a6d35f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best set of hyperparamters found on this dataset setting (GDSC)\n",
    "# net_params = {\n",
    "#  #tunned hyperparameters\n",
    "#  'hidden_units_1': 1024,\n",
    "#  'latent_space': 700,\n",
    "#  'lr': 0.001,\n",
    "#  'dropout': 0.1,\n",
    "#  'mu': 0.01,\n",
    "#  'lambda_': 0.001,\n",
    "#  'gamma': 0.0001,\n",
    "#  'bs': 300,\n",
    "#  'passes': 50,\n",
    "#  'num_tasks': 200,\n",
    "#  'epochs': 100}\n",
    "\n",
    "net_params = {\n",
    "    # Reduzierte GrÃ¶ÃŸen fÃ¼r CPU & Einzel-Drug Training\n",
    "    'hidden_units_1': 64,      # embedding_size in GNNEncoder\n",
    "    'latent_space': 32,        # output_dim in GNNEncoder\n",
    "    'lr': 0.001,               # Lernrate (kann so bleiben)\n",
    "    'dropout': 0.1,            # kann so bleiben\n",
    "    'mu': 0.01,                # L1 Reg.\n",
    "    'lambda_': 0.001,          # L2 Reg.\n",
    "    'gamma': 0.0001,           # Autoencoder Loss weight\n",
    "    'bs': 2,                   # Batch Size runter auf 2â€“4\n",
    "    'passes': 10,              # MC Dropout Simulationen runter\n",
    "    'num_tasks': 1,            # Nur eine Drug!\n",
    "    'epochs': 50               # FÃ¼r schnelles Debugging reichen 50 Epochen\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59d4a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name        | Type       | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | gnn_encoder | GNNEncoder | 42.3 K | train\n",
      "1 | S           | Linear     | 6.6 K  | train\n",
      "2 | A           | Sequential | 6.4 K  | train\n",
      "---------------------------------------------------\n",
      "55.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.3 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n",
      "37        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/sybig/home/tmu/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Train: 536 unique cell lines -> 536 samples\n",
      "  Val:   268 unique cell lines -> 53600 samples\n",
      "Epoch 0:   0%|          | 0/268 [00:00<?, ?it/s] "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[200]' is invalid for input of size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[32m     80\u001b[39m trainer = pl.Trainer(\n\u001b[32m     81\u001b[39m     max_epochs=\u001b[32m50\u001b[39m,\n\u001b[32m     82\u001b[39m     accelerator=\u001b[33m'\u001b[39m\u001b[33mgpu\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m     deterministic=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     86\u001b[39m )\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# 6. Training & Testing\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m results = trainer.test(model, val_loader)\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# 7. Fehler pro Drug speichern\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     51\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    592\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    602\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1017\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1054\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_sanity_check()\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.state\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end()\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_epoch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py:320\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_batch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m         batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    322\u001b[39m         batch_output = \u001b[38;5;28mself\u001b[39m.manual_optimization.run(kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m         closure()\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    267\u001b[39m     \u001b[38;5;28mself\u001b[39m.optim_progress.optimizer.step.increment_ready()\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[32m    280\u001b[39m     \u001b[38;5;28mself\u001b[39m.optim_progress.optimizer.step.increment_completed()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m pl_module._current_fx_name = hook_name\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    179\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/core/module.py:1302\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimizer_step\u001b[39m(\n\u001b[32m   1272\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1273\u001b[39m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1276\u001b[39m     optimizer_closure: Optional[Callable[[], Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1277\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1278\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1279\u001b[39m \u001b[33;03m    the optimizer.\u001b[39;00m\n\u001b[32m   1280\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1300\u001b[39m \n\u001b[32m   1301\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1302\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/core/optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[33m\"\u001b[39m\u001b[33mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/optim/adagrad.py:157\u001b[39m, in \u001b[36mAdagrad.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n\u001b[32m    160\u001b[39m     params_with_grad: \u001b[38;5;28mlist\u001b[39m[Tensor] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/plugins/precision/precision.py:109\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrap_closure\u001b[39m(\n\u001b[32m     97\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     98\u001b[39m     model: \u001b[33m\"\u001b[39m\u001b[33mpl.LightningModule\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     99\u001b[39m     optimizer: Steppable,\n\u001b[32m    100\u001b[39m     closure: Callable[[], Any],\n\u001b[32m    101\u001b[39m ) -> Any:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    hook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     closure_result = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mself\u001b[39m._after_closure(model, optimizer)\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:131\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@torch\u001b[39m.enable_grad()\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> ClosureResult:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    134\u001b[39m         \u001b[38;5;28mself\u001b[39m.warning_cache.warn(\u001b[33m\"\u001b[39m\u001b[33m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:319\u001b[39m, in \u001b[36m_AutomaticOptimization._training_step\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[32m    309\u001b[39m \n\u001b[32m    310\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    315\u001b[39m \n\u001b[32m    316\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    317\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m.trainer\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m training_step_output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.strategy.post_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training_step_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m trainer.world_size > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    331\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py:391\u001b[39m, in \u001b[36mStrategy.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model != \u001b[38;5;28mself\u001b[39m.lightning_module:\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtraining_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 102\u001b[39m, in \u001b[36mtugda_mtl.training_step\u001b[39m\u001b[34m(self, train_batch, batch_idx)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# ðŸš¨ Falls A nicht die richtige Form hat (z. B. bei num_tasks=1), fixe sie manuell:\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight_sum.shape[\u001b[32m0\u001b[39m] != \u001b[38;5;28mself\u001b[39m.num_tasks:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     weight_sum = \u001b[43mweight_sum\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_tasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m a = \u001b[32m1\u001b[39m + (var_preds + weight_sum)  \u001b[38;5;66;03m# [num_tasks]\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Validierungsmaske\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: shape '[200]' is invalid for input of size 32"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Seed setzen (fÃ¼r Reproduzierbarkeit)\n",
    "# -------------------------------\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Liste fÃ¼r Fehler speichern\n",
    "# -------------------------------\n",
    "error_list = []\n",
    "pcorr_list = []  # Falls du Pearson Korrelation spÃ¤ter hinzufÃ¼gst\n",
    "\n",
    "dataset = DrugNetworkDataset(\n",
    "    root=\"./results/Network/\",\n",
    "    drug_list=drug_list,\n",
    "    gene_list=gene_list,\n",
    "    pathway_list=pathway_list,\n",
    "    labels_df=labels_df, \n",
    "    expression_data=expression_data\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Cell Lines splitten (KFold)\n",
    "# -------------------------------\n",
    "all_samples = dataset.samples\n",
    "all_cell_lines = [cl for _, cl in all_samples]\n",
    "unique_cell_lines = list(set(all_cell_lines))\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 1\n",
    "for train_cl_indices, val_cl_indices in kf.split(unique_cell_lines):\n",
    "\n",
    "    # Hole Cell Lines\n",
    "    train_cl = [unique_cell_lines[i] for i in train_cl_indices]\n",
    "    val_cl = [unique_cell_lines[i] for i in val_cl_indices]\n",
    "\n",
    "    # Finde gÃ¼ltige Indices im Dataset\n",
    "    # train_indices = [i for i, (drug, cl) in enumerate(all_samples) if cl in train_cl]\n",
    "\n",
    "    selected_drugs = ['Doxorubicin']\n",
    "    train_indices = [i for i, (drug, cl) in enumerate(all_samples) if cl in train_cl and drug in selected_drugs]\n",
    "\n",
    "    val_indices = [i for i, (drug, cl) in enumerate(all_samples) if cl in val_cl]\n",
    "\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Train: {len(train_cl)} unique cell lines -> {len(train_indices)} samples\")\n",
    "    print(f\"  Val:   {len(val_cl)} unique cell lines -> {len(val_indices)} samples\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4. DataLoader erstellen\n",
    "    # -------------------------------\n",
    "    train_dataset = dataset[train_indices]\n",
    "    val_dataset = dataset[val_indices]\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2, num_workers=0)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5. Seed setzen & Modell erstellen\n",
    "    # -------------------------------\n",
    "    seed = 42\n",
    "    seed_everything(seed)\n",
    "\n",
    "    model = tugda_mtl(net_params, drug_list)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=50,\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1,  # Funktioniert sowohl mit als auch ohne GPU\n",
    "        log_every_n_steps=10,\n",
    "        deterministic=True\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 6. Training & Testing\n",
    "    # -------------------------------\n",
    "    trainer.fit(model, train_loader)\n",
    "    results = trainer.test(model, val_loader)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 7. Fehler pro Drug speichern\n",
    "    # -------------------------------\n",
    "    task_losses = results[0]['test_task_losses_per_class']  # shape: (num_tasks,)\n",
    "    error_mtl_nn_results = np.concatenate((\n",
    "        np.array(drug_list, ndmin=2).T,\n",
    "        np.array(task_losses, ndmin=2).T\n",
    "    ), axis=1)\n",
    "\n",
    "    error_list.append(error_mtl_nn_results)\n",
    "    fold += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
