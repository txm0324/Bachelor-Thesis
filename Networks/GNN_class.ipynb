{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9803ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from torch_geometric.data import Dataset, Data # Installieren\n",
    "import os\n",
    "import numpy as np\n",
    "import torch # Installieren\n",
    "import scipy.sparse # Installieren\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gseapy as gp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d462e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_gmt = gp.parser.get_library('KEGG_2021_Human', organism='Human', min_size=3, max_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23c016f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create files for each list\n",
    "gdsc_dataset = pd.read_csv('/Users/tm03/Desktop/TUGDA_1/data/GDSCDA_fpkm_AUC_all_drugs.zip', index_col=0)\n",
    "gene_list = gdsc_dataset.columns[0:1780]\n",
    "drug_list = gdsc_dataset.columns[1780:] \n",
    "pathway_list = list(kegg_gmt.keys())\n",
    "expression_data = gdsc_dataset.iloc[:, :1780]\n",
    "\n",
    "# combine 3-Fold-Validation Files\n",
    "expression_1 = pd.read_csv(\"/Users/tm03/Desktop/TUGDA_1/data/cl_y_test_o_k1.csv\", index_col=0)\n",
    "expression_2 = pd.read_csv(\"/Users/tm03/Desktop/TUGDA_1/data/cl_y_test_o_k2.csv\", index_col=0)\n",
    "expression_3 = pd.read_csv(\"/Users/tm03/Desktop/TUGDA_1/data/cl_y_test_o_k3.csv\", index_col=0)\n",
    "response_data = pd.concat([expression_1, expression_2, expression_3], axis=0, ignore_index=False)\n",
    "\n",
    "expression_data = expression_data.sort_index()\n",
    "response_data = response_data.sort_index()\n",
    "labels_df = response_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e948bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_data = expression_data[~expression_data.index.duplicated(keep='first')]\n",
    "labels_df = labels_df[~labels_df.index.duplicated(keep='first')]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f586ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugNetworkDataset(Dataset):\n",
    "    def __init__(self, root, drug_list, gene_list, pathway_list, labels_df, expression_data, transform=None, pre_transform=None):\n",
    "        self.drug_list = drug_list\n",
    "        self.gene_list = gene_list\n",
    "        self.pathway_list = pathway_list\n",
    "        self.labels_df = labels_df\n",
    "        self.expression_data = expression_data\n",
    "\n",
    "        # Entferne Duplikate im Index\n",
    "        self.expression_data = self.expression_data[~self.expression_data.index.duplicated(keep='first')]\n",
    "        self.labels_df = self.labels_df[~self.labels_df.index.duplicated(keep='first')]\n",
    "\n",
    "        # Alle Kombinationen aus Drug + Cell Line\n",
    "        self.samples = [\n",
    "            (drug, cell_line) \n",
    "            for drug in self.drug_list \n",
    "            for cell_line in self.labels_df.index\n",
    "        ]\n",
    "\n",
    "        self.custom_raw_dir = os.path.join(root, 'drug_matrices_csv')\n",
    "\n",
    "        super(DrugNetworkDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [f\"{drug}_matrix.csv\" for drug in self.drug_list]\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return self.custom_raw_dir\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['placeholder.pt']  # Dummy, damit Dataset-Klasse nicht meckert\n",
    "\n",
    "    def download(self):\n",
    "        pass  # Nicht benötigt\n",
    "\n",
    "    def _load_adjacency_matrix(self, drug):\n",
    "        \"\"\"Lädt die Adjazenzmatrix für ein Drug\"\"\"\n",
    "        csv_path = os.path.join(self.raw_dir, f\"{drug}_matrix.csv\")\n",
    "        df = pd.read_csv(csv_path, index_col=0)\n",
    "        return df\n",
    "\n",
    "    def _get_node_features(self, nodes, cell_line):\n",
    "        x = []\n",
    "        for node in nodes:\n",
    "            if node in self.gene_list:\n",
    "                expr_value = self.expression_data.loc[cell_line, node]\n",
    "                x.append([float(expr_value)])\n",
    "            elif node in self.pathway_list:\n",
    "                x.append([0.0])\n",
    "            else:\n",
    "                x.append([0.0])\n",
    "        return torch.tensor(x, dtype=torch.float)\n",
    "    \n",
    "    def get_node_name_by_index(self, idx, node_index):\n",
    "        drug, cell_line = self.samples[idx]\n",
    "        \n",
    "        # Lade die Adjazenzmatrix → gibt dir die Knotenliste\n",
    "        adj_df = self._load_adjacency_matrix(drug)\n",
    "        nodes = adj_df.columns.tolist()\n",
    "        \n",
    "        if node_index < len(nodes):\n",
    "            return nodes[node_index]\n",
    "        else:\n",
    "            raise IndexError(f\"Node index {node_index} out of range for this graph.\")\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def get(self, idx):\n",
    "        drug, cell_line = self.samples[idx]\n",
    "\n",
    "        # 1. Adjazenzmatrix laden\n",
    "        adj_df = self._load_adjacency_matrix(drug)\n",
    "        nodes = adj_df.columns.tolist()\n",
    "        adj_matrix = adj_df.values\n",
    "\n",
    "        # 2. Edge-Index bauen\n",
    "        edge_index = torch.tensor(np.array(np.nonzero(adj_matrix)), dtype=torch.long)\n",
    "\n",
    "        # 3. Node Features\n",
    "        x = self._get_node_features(nodes, cell_line)\n",
    "\n",
    "        # 4. Label\n",
    "        y = torch.tensor([self.labels_df.loc[cell_line, drug]], dtype=torch.float)\n",
    "\n",
    "        # 5. Data-Objekt erstellen\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, drug=drug, cell_line=cell_line)\n",
    "        data.nodes = nodes\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b39ccf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DrugNetworkDataset(\n",
    "    root=\"./results/Network/\",\n",
    "    drug_list=drug_list,\n",
    "    gene_list=gene_list,\n",
    "    pathway_list=pathway_list,\n",
    "    labels_df=labels_df, \n",
    "    expression_data=expression_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1e055da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug Name: Camptothecin\n",
      "Cell Line Name: 22RV1\n",
      "Edge Index:\n",
      "tensor([[   0,    0],\n",
      "        [   0,  182],\n",
      "        [   0,  195],\n",
      "        ...,\n",
      "        [1337, 1337],\n",
      "        [1338,  418],\n",
      "        [1338, 1338]])\n",
      "torch.Size([22505, 2])\n",
      "\n",
      "Node Features (x):\n",
      "tensor([[-0.8910],\n",
      "        [ 0.5178],\n",
      "        [-0.5985],\n",
      "        ...,\n",
      "        [-0.1359],\n",
      "        [ 0.6368],\n",
      "        [ 0.6063]])\n",
      "torch.Size([1339, 1])\n",
      "Index 0: ABL1 → Feature: -0.8910\n",
      "Index 1: ACVR1B → Feature: 0.5178\n",
      "Index 2: ADORA1 → Feature: -0.5985\n",
      "Index 3: AR → Feature: 4.2872\n",
      "Index 4: ATF4 → Feature: -0.1862\n",
      "Index 5: ATM → Feature: -0.3401\n",
      "Index 6: ATR → Feature: -0.1959\n",
      "Index 7: AURKA → Feature: -0.3216\n",
      "Index 8: BAX → Feature: -0.6138\n",
      "Index 9: BBC3 → Feature: 0.4687\n",
      "\n",
      "Label (y):\n",
      "tensor([-3.1426])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "\n",
    "print(\"Drug Name:\", data.drug)\n",
    "print(\"Cell Line Name:\", data.cell_line)\n",
    "\n",
    "print(\"Edge Index:\")\n",
    "print(data.edge_index.t())\n",
    "print(data.edge_index.t().shape)\n",
    "\n",
    "print(\"\\nNode Features (x):\")\n",
    "print(data.x)\n",
    "print(data.x.shape)\n",
    "\n",
    "nodes = data.nodes\n",
    "\n",
    "for i in range(10):\n",
    "    node_name = nodes[i]\n",
    "    feature_value = data.x[i].item()\n",
    "    print(f\"Index {i}: {node_name} → Feature: {feature_value:.4f}\")\n",
    "\n",
    "print(\"\\nLabel (y):\")\n",
    "print(data.y)\n",
    "print(data.y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd73cf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ABL1\n",
      "22RV1    -0.890968\n",
      "23132-87 -1.569799\n",
      "42-MG-BA  0.536505\n",
      "5637      0.873951\n",
      "639-V    -0.708590\n",
      "...            ...\n",
      "YAPC      0.712502\n",
      "YH-13     1.926564\n",
      "YT       -2.203333\n",
      "ZR-75-30 -0.708590\n",
      "huH-1    -0.890968\n",
      "\n",
      "[804 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "print(expression_data[[\"ABL1\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70859eb8",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc51fb5c",
   "metadata": {},
   "source": [
    "Komponenten: \n",
    "- GNNEncoder: Drug-Specific Network Graphen \n",
    "- Aim: tugda_mtl verarbeitet Rohdaten aus Expressionsprofilen --> Drug-spezfische Graphen aus DrugNetworkDataset verwenden, GNN-Encoder als Feature Extractor einbauen \n",
    "\n",
    "- Wir ersetzen:\n",
    "- Die bisherigen nn.Linear-Schichten durch den GNNEncoder. Die Eingabe von X_train durch drug_data (vom Typ Data). Der Output des Encoders wird an die S, A etc. Schichten weitergeleitet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "37a1cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(self, feature_size=1, embedding_size=512, output_dim=256):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "\n",
    "        # GNN Layers\n",
    "        self.conv1 = GATConv(feature_size, embedding_size, heads=3, dropout=0.6)\n",
    "        self.head_transform1 = nn.Linear(embedding_size * 3, embedding_size)\n",
    "        self.bn1 = nn.BatchNorm1d(embedding_size)\n",
    "        self.pool1 = TopKPooling(embedding_size, ratio=0.8)\n",
    "\n",
    "        self.conv2 = GATConv(embedding_size, embedding_size, heads=3, dropout=0.6)\n",
    "        self.head_transform2 = nn.Linear(embedding_size * 3, embedding_size)\n",
    "        self.bn2 = nn.BatchNorm1d(embedding_size)\n",
    "        self.pool2 = TopKPooling(embedding_size, ratio=0.5)\n",
    "\n",
    "        self.conv3 = GATConv(embedding_size, embedding_size, heads=3, dropout=0.6)\n",
    "        self.head_transform3 = nn.Linear(embedding_size * 3, embedding_size)\n",
    "        self.bn3 = nn.BatchNorm1d(embedding_size)\n",
    "        self.pool3 = TopKPooling(embedding_size, ratio=0.2)\n",
    "\n",
    "        # Final projection\n",
    "        self.linear1 = nn.Linear(embedding_size * 2, 512)\n",
    "        self.linear2 = nn.Linear(512, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # First Block\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(self.head_transform1(x))\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        # Second Block\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(self.head_transform2(x))\n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        # Third Block\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(self.head_transform3(x))\n",
    "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        # Combine pooled features\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        # Final layers\n",
    "        x = self.linear1(x).relu()\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        graph_embedding = self.linear2(x)\n",
    "\n",
    "        return graph_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cc83d913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Echtes Embedding Shape: torch.Size([1, 256])\n",
      "tensor([[ 0.0416, -0.0418, -0.0064, -0.0336,  0.0083, -0.0032,  0.0064, -0.0348,\n",
      "          0.0170,  0.0100, -0.0263,  0.0370, -0.0149,  0.0343,  0.0127, -0.0105,\n",
      "         -0.0248, -0.0263,  0.0216, -0.0502,  0.0193,  0.0387, -0.0115, -0.0072,\n",
      "          0.0065,  0.0292,  0.0005, -0.0315, -0.0124, -0.0299,  0.0396, -0.0292,\n",
      "         -0.0184, -0.0171,  0.0421, -0.0211,  0.0296,  0.0060, -0.0079,  0.0204,\n",
      "         -0.0182,  0.0210, -0.0380, -0.0179,  0.0075,  0.0362,  0.0327, -0.0203,\n",
      "         -0.0386,  0.0243, -0.0028,  0.0519,  0.0480, -0.0109,  0.0186, -0.0027,\n",
      "         -0.0100, -0.0132,  0.0316, -0.0089,  0.0231, -0.0022, -0.0098, -0.0124,\n",
      "          0.0508, -0.0189,  0.0070,  0.0277,  0.0263,  0.0277, -0.0169,  0.0167,\n",
      "         -0.0045,  0.0102, -0.0247, -0.0313,  0.0104,  0.0041, -0.0474,  0.0233,\n",
      "         -0.0481,  0.0526, -0.0039, -0.0140, -0.0386, -0.0350, -0.0024,  0.0520,\n",
      "          0.0157, -0.0334,  0.0287, -0.0038, -0.0131, -0.0184,  0.0228,  0.0222,\n",
      "         -0.0422,  0.0082, -0.0153,  0.0005, -0.0135, -0.0493, -0.0057,  0.0004,\n",
      "          0.0011,  0.0386, -0.0127,  0.0271, -0.0420,  0.0366, -0.0521, -0.0365,\n",
      "         -0.0375, -0.0260, -0.0276, -0.0448, -0.0153,  0.0339, -0.0003, -0.0152,\n",
      "         -0.0006,  0.0146, -0.0293, -0.0329, -0.0238, -0.0092, -0.0199, -0.0074,\n",
      "          0.0077,  0.0210,  0.0108, -0.0434, -0.0307,  0.0097, -0.0340,  0.0218,\n",
      "         -0.0050,  0.0133, -0.0297, -0.0120,  0.0050,  0.0482,  0.0261,  0.0436,\n",
      "         -0.0268, -0.0099, -0.0416, -0.0185, -0.0098,  0.0112,  0.0338,  0.0124,\n",
      "         -0.0265,  0.0107, -0.0490, -0.0068,  0.0003, -0.0412,  0.0496, -0.0063,\n",
      "         -0.0264,  0.0134, -0.0295,  0.0158, -0.0277, -0.0201,  0.0250,  0.0008,\n",
      "         -0.0197,  0.0301,  0.0461,  0.0117,  0.0357,  0.0223, -0.0424, -0.0456,\n",
      "         -0.0389,  0.0229, -0.0387,  0.0476, -0.0355,  0.0433, -0.0276,  0.0393,\n",
      "          0.0283, -0.0042, -0.0161, -0.0134,  0.0021, -0.0154,  0.0452,  0.0060,\n",
      "          0.0228, -0.0384, -0.0227, -0.0081,  0.0083,  0.0026,  0.0062,  0.0264,\n",
      "          0.0389, -0.0288,  0.0105,  0.0220,  0.0015, -0.0011, -0.0115, -0.0408,\n",
      "         -0.0089,  0.0279, -0.0288,  0.0201, -0.0012, -0.0383,  0.0251, -0.0238,\n",
      "          0.0056, -0.0126,  0.0126, -0.0589, -0.0262,  0.0118,  0.0385,  0.0423,\n",
      "          0.0491, -0.0188,  0.0121, -0.0375,  0.0290,  0.0331, -0.0315,  0.0454,\n",
      "          0.0102,  0.0026,  0.0530, -0.0362, -0.0039, -0.0101, -0.0220,  0.0157,\n",
      "         -0.0545,  0.0254,  0.0456, -0.0108,  0.0013,  0.0003, -0.0342,  0.0247,\n",
      "          0.0012, -0.0446,  0.0513,  0.0128,  0.0301, -0.0269, -0.0133, -0.0236]])\n"
     ]
    }
   ],
   "source": [
    "# Hole einen echten Datensatz\n",
    "data = dataset[0]  # Dataset[Index] gibt ein Data-Objekt zurück\n",
    "\n",
    "# Encoder aufrufen\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    embedding = encoder(data)\n",
    "\n",
    "print(\"Echtes Embedding Shape:\", embedding.shape)\n",
    "print(embedding)\n",
    "\n",
    "# Output: Gewichte in einem latenten Raum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c930e",
   "metadata": {},
   "source": [
    "# Cell Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7e19c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell_EmbedNet(nn.Module):\n",
    "    def __init__(self, fc_in_dim=1780, fc_hid_dim=[512, 512], embed_dim=256, dropout=0.5):\n",
    "        super(Cell_EmbedNet, self).__init__()\n",
    "        self.fc_hid_dim = fc_hid_dim\n",
    "        self.fc = nn.Linear(fc_in_dim, self.fc_hid_dim[0])\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = dropout\n",
    "        self.classifier = nn.ModuleList()\n",
    "\n",
    "        for input_size, output_size in zip(self.fc_hid_dim, self.fc_hid_dim[1:]):\n",
    "            self.classifier.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(input_size, output_size),\n",
    "                    nn.BatchNorm1d(output_size),\n",
    "                    self.act,\n",
    "                    nn.Dropout(p=self.dropout)\n",
    "                )\n",
    "            )\n",
    "        self.fc2 = nn.Linear(self.fc_hid_dim[-1], embed_dim)\n",
    "\n",
    "        # Weight init\n",
    "        for layer in self.classifier:\n",
    "            nn.init.xavier_uniform_(layer[0].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        for fc in self.classifier:\n",
    "            x = fc(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c6341297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugCellPredictor(nn.Module):\n",
    "    def __init__(self, input_dim=512, hidden_dim=256):\n",
    "        super(DrugCellPredictor, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, 1)  # Ausgabe: z.B. AUC-Wert\n",
    "        )\n",
    "\n",
    "    def forward(self, drug_emb, cell_emb):\n",
    "        combined = torch.cat([drug_emb, cell_emb], dim=1)  # shape: [batch_size, 512]\n",
    "        prediction = self.mlp(combined)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugResponseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gnn_encoder = GNNEncoder(output_dim=256)\n",
    "        self.cell_encoder = Cell_EmbedNet(fc_in_dim=1780, embed_dim=256)\n",
    "        self.predictor = DrugCellPredictor(input_dim=512)\n",
    "\n",
    "    def forward(self, drug_data, cell_expression):\n",
    "        drug_emb = self.gnn_encoder(drug_data)\n",
    "        cell_emb = self.cell_encoder(cell_expression)\n",
    "        prediction = self.predictor(drug_emb, cell_emb)\n",
    "        return prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
