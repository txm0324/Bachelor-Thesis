{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "274df7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================\n",
      "Step 0: Download and Preprocess\n",
      "===============================\n",
      "          Oxaliplatin  Ulixertinib  Fulvestrant  Uprosertib  Dactinomycin  \\\n",
      "22RV1        3.081337     2.803572     4.227332    1.133014     -4.923521   \n",
      "23132-87     4.391634     2.526244     3.697545    0.188871     -4.530814   \n",
      "42-MG-BA     4.129735     3.147708     4.045351    1.682197     -4.231256   \n",
      "5637         4.391109     2.884360     3.535578    4.453362     -4.262836   \n",
      "639-V        3.253815     2.546112     3.550254    4.297324     -4.760262   \n",
      "...               ...          ...          ...         ...           ...   \n",
      "YAPC         5.245318     4.309617     4.761417    5.532699     -2.255783   \n",
      "YH-13        3.945620     3.377953     3.812616    2.172373     -3.734196   \n",
      "YT           0.461330     1.745128     2.024318    4.395238     -5.679264   \n",
      "ZR-75-30     7.154014     6.182055     5.587853    3.443328     -0.055238   \n",
      "huH-1        6.006727     4.090465     4.028713    3.325009     -0.850808   \n",
      "\n",
      "          Docetaxel  Camptothecin  5-Fluorouracil  Afatinib  Taselisib  ...  \\\n",
      "22RV1     -2.941937     -3.142631        2.478859  2.433064   0.972964  ...   \n",
      "23132-87  -5.210999     -3.276945        2.168003  0.652471  -0.320857  ...   \n",
      "42-MG-BA  -4.247072     -2.906706        3.362543  1.723549   0.896352  ...   \n",
      "5637      -5.553314     -2.314530        3.313258 -0.036451   1.822476  ...   \n",
      "639-V     -4.869332     -5.115998        4.410077  1.728613   2.683493  ...   \n",
      "...             ...           ...             ...       ...        ...  ...   \n",
      "YAPC       1.326340     -1.756217        5.638735  2.535585   2.528939  ...   \n",
      "YH-13     -5.772570     -1.462977        4.882430  2.042245   0.323799  ...   \n",
      "YT        -4.989452     -4.794935        0.759572  1.746264   0.800917  ...   \n",
      "ZR-75-30   1.329350      2.638266        7.142114 -1.255299   2.513473  ...   \n",
      "huH-1     -2.344459     -1.004498        6.373681  2.990538   3.620741  ...   \n",
      "\n",
      "          BMS-754807   BI-2536  Cetuximab  Doxorubicin  Etoposide  Bleomycin  \\\n",
      "22RV1            NaN       NaN   6.683803    -2.500206   0.246500   1.938966   \n",
      "23132-87         NaN       NaN   6.296225    -3.525237  -0.488340  -0.510824   \n",
      "42-MG-BA         NaN       NaN   6.367809    -2.129720   2.420287   2.128587   \n",
      "5637             NaN       NaN   5.181353    -3.009819  -0.207230  -1.679493   \n",
      "639-V            NaN       NaN   5.332501    -3.358160   0.188715  -1.227591   \n",
      "...              ...       ...        ...          ...        ...        ...   \n",
      "YAPC             NaN       NaN   7.164002     0.239293   3.578462   6.961423   \n",
      "YH-13            NaN       NaN        NaN    -0.721920   4.373041   4.716770   \n",
      "YT               NaN       NaN   6.334848    -0.093297   2.301408   0.431449   \n",
      "ZR-75-30         NaN  3.724833        NaN     1.044187        NaN        NaN   \n",
      "huH-1            NaN       NaN   6.136704     0.620599   5.166316   5.241475   \n",
      "\n",
      "          Bicalutamide  Bleomycin (50 uM)  Pemetrexed  AICA Ribonucleotide  \n",
      "22RV1         3.673067           4.031290    1.456603             8.277725  \n",
      "23132-87      3.465794           0.525526    0.506745             8.505100  \n",
      "42-MG-BA      3.524764          -0.450167    2.582966             7.562607  \n",
      "5637          3.206796          -0.494399    0.572228             8.011649  \n",
      "639-V         3.151029           0.061915    2.500569             7.448760  \n",
      "...                ...                ...         ...                  ...  \n",
      "YAPC          3.812996           2.382738    1.303840             9.325474  \n",
      "YH-13         3.498026           1.017930    3.711630             9.043458  \n",
      "YT            3.118420           4.505120    2.112467             8.023384  \n",
      "ZR-75-30           NaN           7.171414         NaN             8.513561  \n",
      "huH-1         4.172252           3.268635    4.467953             7.678649  \n",
      "\n",
      "[804 rows x 200 columns]\n",
      "\n",
      "==========================\n",
      "Step 1: 3-Cross-Validation\n",
      "==========================\n",
      "Generating training and test data...\n",
      "\n",
      "--- Fold 1 ---\n",
      "Start building Train Dataset\n",
      "536\n",
      "Start building Test Dataset\n",
      "268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sybig/home/tmu/Schreibtisch/Bachelor-Thesis/Networks/Train_Test_Data.py:49: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  labels_long = labels_df.stack(dropna=False).reset_index()\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 2 ---\n",
      "Start building Train Dataset\n",
      "536\n",
      "Start building Test Dataset\n",
      "268\n",
      "\n",
      "--- Fold 3 ---\n",
      "Start building Train Dataset\n",
      "536\n",
      "Start building Test Dataset\n",
      "268\n"
     ]
    }
   ],
   "source": [
    "from Train_Test_Data import train_datasets, test_datasets\n",
    "from Train_Test_Data import drug_list\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#call pytorch lightning functions\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Callback\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "from torch_geometric.data import DataLoader as GeoDataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfdc20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, TopKPooling, global_max_pool as gmp, global_mean_pool as gap\n",
    "\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(self, feature_size=3, embedding_size=512, output_dim=256):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "\n",
    "        # Block 1\n",
    "        self.conv1 = GATConv(feature_size, embedding_size, heads=3, dropout=0.6)\n",
    "        self.head_transform1 = nn.Linear(embedding_size * 3, embedding_size)\n",
    "        self.bn1 = nn.BatchNorm1d(embedding_size)\n",
    "        self.pool1 = TopKPooling(embedding_size, ratio=0.8)\n",
    "\n",
    "        # Block 2\n",
    "        self.conv2 = GATConv(embedding_size, embedding_size, heads=3, dropout=0.6)\n",
    "        self.head_transform2 = nn.Linear(embedding_size * 3, embedding_size)\n",
    "        self.bn2 = nn.BatchNorm1d(embedding_size)\n",
    "        self.pool2 = TopKPooling(embedding_size, ratio=0.5)\n",
    "\n",
    "        # Final projection\n",
    "        self.linear1 = nn.Linear(embedding_size * 2, 512)\n",
    "        self.linear2 = nn.Linear(512, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # Block 1\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(self.head_transform1(x))\n",
    "        x = self.bn1(x)\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        # Block 2\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(self.head_transform2(x))\n",
    "        x = self.bn2(x)\n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        # Combine\n",
    "        x = x1 + x2\n",
    "\n",
    "        # Final layers\n",
    "        x = self.linear1(x).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        graph_embedding = self.linear2(x)\n",
    "\n",
    "        return graph_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c43508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(Callback):\n",
    "    \"\"\"PyTorch Lightning metric callback.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metrics = []\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        self.metrics.append(trainer.callback_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e89ad4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9923c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tugda_mtl_gnn(pl.LightningModule):\n",
    "    def __init__(self, params, train_dataset, y_train, test_dataset, y_test):\n",
    "        super(tugda_mtl_gnn, self).__init__()\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.learning_rate = params['lr']\n",
    "        self.batch_size = params['bs']\n",
    "        self.mu = params['mu']\n",
    "        self.lambda_ = params['lambda_']\n",
    "        self.gamma = params['gamma']\n",
    "        self.num_tasks = params['num_tasks']\n",
    "        self.passes = params['passes']\n",
    "\n",
    "        # Data\n",
    "        self.train_data = train_dataset\n",
    "        self.y_train = y_train\n",
    "        self.test_data = test_dataset\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        # GNN Encoder (your existing implementation)\n",
    "        self.gnn_encoder = GNNEncoder(\n",
    "            feature_size=params.get('feature_size', 3),\n",
    "            embedding_size=params.get('embedding_size', 128),\n",
    "            output_dim=params.get('gnn_output_dim', 64)\n",
    "        )\n",
    "\n",
    "        # Projection layer\n",
    "        projection = [\n",
    "            nn.Linear(params.get('gnn_output_dim', 256), params['hidden_units_1']),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        self.projection = nn.Sequential(*projection)\n",
    "        \n",
    "        # Latent basis\n",
    "        latent_basis = [\n",
    "            nn.Linear(params['hidden_units_1'], params['latent_space']),\n",
    "            nn.Dropout(p=params['dropout']),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        self.latent_basis = nn.Sequential(*latent_basis)\n",
    "        \n",
    "        # Task-specific weights\n",
    "        self.S = nn.Linear(params['latent_space'], self.num_tasks)\n",
    "        \n",
    "        # Decoder weights\n",
    "        A = [nn.Linear(self.num_tasks, params['latent_space']), nn.ReLU()]\n",
    "        self.A = nn.Sequential(*A)\n",
    "        \n",
    "        # Uncertainty (aleatoric)\n",
    "        self.log_vars = torch.zeros(self.num_tasks, requires_grad=True, device=device)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # Process graph data through GNN encoder\n",
    "        graph_embedding = self.gnn_encoder(data)\n",
    "        \n",
    "        # Project to hidden dimension\n",
    "        x = self.projection(graph_embedding)\n",
    "        \n",
    "        # Continue with original TUGDA architecture\n",
    "        h = self.latent_basis(x)\n",
    "        preds = self.S(h)\n",
    "        h_hat = self.A(preds)\n",
    "        return preds, h, h_hat\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.train_dataset = self.train_data\n",
    "        self.test_dataset = self.test_data\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        from torch_geometric.loader import DataLoader\n",
    "        return DataLoader(self.train_dataset, \n",
    "                        batch_size=self.batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        from torch_geometric.loader import DataLoader\n",
    "        return DataLoader(self.test_dataset,\n",
    "                        batch_size=len(self.test_dataset),\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        params = ([p for p in self.parameters()] + [self.log_vars])\n",
    "        optimizer = torch.optim.Adagrad(params, lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_closure):\n",
    "        \"\"\"\n",
    "        Proper implementation of optimizer_step that handles the closure\n",
    "        \"\"\"\n",
    "        # Call the closure to compute the loss and gradients\n",
    "        optimizer_closure()\n",
    "        \n",
    "        # Perform the actual optimization step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    def mse_ignore_nan(self, preds, labels):\n",
    "        mse_loss = torch.nn.MSELoss(reduction='none')\n",
    "        per_task_loss = torch.zeros(labels.size(1), device=device)\n",
    "\n",
    "        for k in range(labels.size(1)):\n",
    "            precision = torch.exp(-self.log_vars[k])\n",
    "            diff = mse_loss(preds[~torch.isnan(labels[:,k]), k], labels[~torch.isnan(labels[:,k]), k])\n",
    "            per_task_loss[k] = torch.mean(precision * diff + self.log_vars[k])\n",
    "\n",
    "        return torch.mean(per_task_loss[~torch.isnan(per_task_loss)]), per_task_loss\n",
    "    \n",
    "    def mse_ignore_nan_test(self, preds, labels):\n",
    "        mse_loss = torch.nn.MSELoss(reduction='mean')\n",
    "        per_task_loss = torch.zeros(labels.size(1), device=device)\n",
    "        \n",
    "        for k in range(labels.size(1)):\n",
    "            per_task_loss[k] = mse_loss(preds[~torch.isnan(labels[:,k]), k], labels[~torch.isnan(labels[:,k]), k])\n",
    "            \n",
    "        return torch.mean(per_task_loss[~torch.isnan(per_task_loss)]), per_task_loss \n",
    "    \n",
    "    def MSE_loss(self, x, x_hat):\n",
    "        mse_loss = torch.nn.MSELoss()\n",
    "        return mse_loss(x, x_hat)\n",
    "    \n",
    "    def forward_pass(self, batch, batch_idx):\n",
    "        # print(\"Type of batch:\", type(batch))\n",
    "        # print(\"Length of batch:\", len(batch))  # Wie viele Cell Lines im Batch?\n",
    "        # print(\"Type of first element:\", type(batch[0]))\n",
    "        # print(\"First element keys:\", batch[0][0].keys())  # Zeigt an, welche Attribute der Graph hat\n",
    "\n",
    " \n",
    "        cell_line_graphs = batch[0]  # Liste von Drug-Graphen\n",
    "        labels = batch[1]            # shape: [num_drugs]\n",
    "        labels = labels.squeeze(1)\n",
    "\n",
    "        # print(type(cell_line_graphs)) \n",
    "        # print(len(cell_line_graphs)) \n",
    "        # print(labels)\n",
    "        # print(labels.shape)\n",
    "\n",
    "        all_embeddings = []\n",
    "\n",
    "        for graph in cell_line_graphs:\n",
    "            # GNN Encoder aufrufen\n",
    "            graph_emb = self.gnn_encoder(graph)  # shape: [1, output_dim]\n",
    "            all_embeddings.append(graph_emb)\n",
    "\n",
    "        # Staple alle Embeddings\n",
    "        graph_embeddings = torch.cat(all_embeddings, dim=0)  # shape: [num_drugs, output_dim]\n",
    "\n",
    "        # Projektion in latenten Raum\n",
    "        h = self.latent_basis(graph_embeddings)\n",
    "\n",
    "        # Task-spezifische Vorhersage\n",
    "        preds = self.S(h).squeeze(1)  # shape: [num_cell_lines, num_tasks]\n",
    "\n",
    "        # Loss-Berechnung\n",
    "        local_loss, task_loss = self.mse_ignore_nan(preds, labels)\n",
    "\n",
    "        recon_loss = self.gamma * self.MSE_loss(h, ...)  # optional\n",
    "\n",
    "        # Regularisierungen\n",
    "        a = 1 + torch.sum(torch.abs(self.A[0].weight.T), 1)\n",
    "        loss_weight = (a[~torch.isnan(task_loss)]) * task_loss[~torch.isnan(task_loss)]\n",
    "        loss_weight = torch.sum(loss_weight)\n",
    "        l1_S = self.mu * self.S.weight.norm(1)\n",
    "        L = self.latent_basis[0].weight.norm(2) + self.gnn_encoder.norm().norm(2)\n",
    "        l2_L = self.lambda_ * L\n",
    "\n",
    "        total_loss = loss_weight + recon_loss + l1_S + l2_L\n",
    "\n",
    "        return total_loss, task_loss\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # batch is a PyG Data object, no need to unpack\n",
    "        loss, task_loss = self.forward_pass(batch, batch_idx)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        # Enable dropouts in GNN encoder\n",
    "        for module in self.gnn_encoder.modules():\n",
    "            if isinstance(module, nn.Dropout):\n",
    "                module.train()\n",
    "\n",
    "        y = test_batch.y  # shape: [batch_size, num_tasks]\n",
    "        preds_simulation = torch.zeros(y.size(0), y.size(1), self.passes, device=self.device)\n",
    "\n",
    "        for simulation in range(self.passes):\n",
    "            seed = simulation\n",
    "            pl.seed_everything(seed)\n",
    "            preds, _, _ = self.forward(test_batch)\n",
    "            preds_simulation[:, :, simulation] = preds\n",
    "\n",
    "        preds_mean = torch.mean(preds_simulation, dim=2)\n",
    "        loss, task_losses_per_class = self.mse_ignore_nan_test(preds_mean, y)\n",
    "\n",
    "        # Disable dropouts\n",
    "        self.eval()\n",
    "\n",
    "        return {\n",
    "            'test_loss': loss,\n",
    "            'test_task_losses_per_class': task_losses_per_class.detach().cpu().numpy(),\n",
    "            'test_preds': preds_mean.detach().cpu().numpy(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb88952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best set of hyperparamters found on this dataset setting (GDSC)\n",
    "net_params = {\n",
    " #tunned hyperparameters\n",
    " 'hidden_units_1': 512,\n",
    " 'latent_space': 256,\n",
    " 'lr': 0.001,\n",
    " 'dropout': 0.1,\n",
    " 'mu': 0.01,\n",
    " 'lambda_': 0.001,\n",
    " 'gamma': 0.0001,\n",
    " 'bs': 8,\n",
    " 'passes': 10,\n",
    " 'num_tasks': 200,\n",
    " 'epochs': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afde0435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([Data(x=[1785, 3], edge_index=[2, 47063], y=[1], drug='Oxaliplatin', cell_line='22RV1', nodes=[1785]), Data(x=[1783, 3], edge_index=[2, 48145], y=[1], drug='Ulixertinib', cell_line='22RV1', nodes=[1783]), Data(x=[1925, 3], edge_index=[2, 76685], y=[1], drug='Fulvestrant', cell_line='22RV1', nodes=[1925]), Data(x=[1776, 3], edge_index=[2, 47986], y=[1], drug='Uprosertib', cell_line='22RV1', nodes=[1776]), Data(x=[1841, 3], edge_index=[2, 56445], y=[1], drug='Dactinomycin', cell_line='22RV1', nodes=[1841]), Data(x=[1754, 3], edge_index=[2, 45226], y=[1], drug='Docetaxel', cell_line='22RV1', nodes=[1754]), Data(x=[1827, 3], edge_index=[2, 52461], y=[1], drug='Camptothecin', cell_line='22RV1', nodes=[1827]), Data(x=[1703, 3], edge_index=[2, 35167], y=[1], drug='5-Fluorouracil', cell_line='22RV1', nodes=[1703]), Data(x=[1849, 3], edge_index=[2, 59683], y=[1], drug='Afatinib', cell_line='22RV1', nodes=[1849]), Data(x=[1669, 3], edge_index=[2, 32873], y=[1], drug='Taselisib', cell_line='22RV1', nodes=[1669]), Data(x=[1838, 3], edge_index=[2, 56238], y=[1], drug='PD0325901', cell_line='22RV1', nodes=[1838]), Data(x=[1779, 3], edge_index=[2, 47395], y=[1], drug='Sapitinib', cell_line='22RV1', nodes=[1779]), Data(x=[1805, 3], edge_index=[2, 52235], y=[1], drug='Alpelisib', cell_line='22RV1', nodes=[1805]), Data(x=[1602, 3], edge_index=[2, 31342], y=[1], drug='SCH772984', cell_line='22RV1', nodes=[1602]), Data(x=[1603, 3], edge_index=[2, 28527], y=[1], drug='LGK974', cell_line='22RV1', nodes=[1603]), Data(x=[1621, 3], edge_index=[2, 28985], y=[1], drug='Luminespib', cell_line='22RV1', nodes=[1621]), Data(x=[1792, 3], edge_index=[2, 48410], y=[1], drug='Linsitinib', cell_line='22RV1', nodes=[1792]), Data(x=[1708, 3], edge_index=[2, 40274], y=[1], drug='GSK1904529A', cell_line='22RV1', nodes=[1708]), Data(x=[1572, 3], edge_index=[2, 27092], y=[1], drug='EPZ5676', cell_line='22RV1', nodes=[1572]), Data(x=[1609, 3], edge_index=[2, 27955], y=[1], drug='EPZ004777', cell_line='22RV1', nodes=[1609]), Data(x=[1831, 3], edge_index=[2, 54169], y=[1], drug='Irinotecan', cell_line='22RV1', nodes=[1831]), Data(x=[1834, 3], edge_index=[2, 54768], y=[1], drug='PLX-4720', cell_line='22RV1', nodes=[1834]), Data(x=[1640, 3], edge_index=[2, 29782], y=[1], drug='Nutlin-3a (-)', cell_line='22RV1', nodes=[1640]), Data(x=[1619, 3], edge_index=[2, 29345], y=[1], drug='MG-132', cell_line='22RV1', nodes=[1619]), Data(x=[1873, 3], edge_index=[2, 63261], y=[1], drug='Staurosporine', cell_line='22RV1', nodes=[1873]), Data(x=[1785, 3], edge_index=[2, 47319], y=[1], drug='MK-2206', cell_line='22RV1', nodes=[1785]), Data(x=[1801, 3], edge_index=[2, 52169], y=[1], drug='Trametinib', cell_line='22RV1', nodes=[1801]), Data(x=[1857, 3], edge_index=[2, 61145], y=[1], drug='Palbociclib', cell_line='22RV1', nodes=[1857]), Data(x=[1794, 3], edge_index=[2, 49574], y=[1], drug='MK-1775', cell_line='22RV1', nodes=[1794]), Data(x=[1952, 3], edge_index=[2, 93940], y=[1], drug='Cisplatin', cell_line='22RV1', nodes=[1952]), Data(x=[1850, 3], edge_index=[2, 58602], y=[1], drug='Pictilisib', cell_line='22RV1', nodes=[1850]), Data(x=[1792, 3], edge_index=[2, 49042], y=[1], drug='AZD7762', cell_line='22RV1', nodes=[1792]), Data(x=[1732, 3], edge_index=[2, 37348], y=[1], drug='Olaparib', cell_line='22RV1', nodes=[1732]), Data(x=[1795, 3], edge_index=[2, 52793], y=[1], drug='Dasatinib', cell_line='22RV1', nodes=[1795]), Data(x=[1609, 3], edge_index=[2, 29669], y=[1], drug='AZD3759', cell_line='22RV1', nodes=[1609]), Data(x=[1814, 3], edge_index=[2, 51012], y=[1], drug='PD173074', cell_line='22RV1', nodes=[1814]), Data(x=[1906, 3], edge_index=[2, 73376], y=[1], drug='Vorinostat', cell_line='22RV1', nodes=[1906]), Data(x=[1808, 3], edge_index=[2, 52398], y=[1], drug='Dabrafenib', cell_line='22RV1', nodes=[1808]), Data(x=[1866, 3], edge_index=[2, 66926], y=[1], drug='Paclitaxel', cell_line='22RV1', nodes=[1866]), Data(x=[1618, 3], edge_index=[2, 29940], y=[1], drug='AZD4547', cell_line='22RV1', nodes=[1618]), Data(x=[1867, 3], edge_index=[2, 62959], y=[1], drug='Lapatinib', cell_line='22RV1', nodes=[1867]), Data(x=[1888, 3], edge_index=[2, 70270], y=[1], drug='Sorafenib', cell_line='22RV1', nodes=[1888]), Data(x=[1840, 3], edge_index=[2, 57424], y=[1], drug='Nilotinib', cell_line='22RV1', nodes=[1840]), Data(x=[1847, 3], edge_index=[2, 64807], y=[1], drug='Tamoxifen', cell_line='22RV1', nodes=[1847]), Data(x=[1815, 3], edge_index=[2, 54193], y=[1], drug='Gemcitabine', cell_line='22RV1', nodes=[1815]), Data(x=[1702, 3], edge_index=[2, 35494], y=[1], drug='Venetoclax', cell_line='22RV1', nodes=[1702]), Data(x=[1839, 3], edge_index=[2, 59173], y=[1], drug='Bortezomib', cell_line='22RV1', nodes=[1839]), Data(x=[1712, 3], edge_index=[2, 38754], y=[1], drug='Wee1 Inhibitor', cell_line='22RV1', nodes=[1712]), Data(x=[1808, 3], edge_index=[2, 52668], y=[1], drug='Osimertinib', cell_line='22RV1', nodes=[1808]), Data(x=[1570, 3], edge_index=[2, 27508], y=[1], drug='AGI-5198', cell_line='22RV1', nodes=[1570]), Data(x=[1603, 3], edge_index=[2, 29171], y=[1], drug='Ipatasertib', cell_line='22RV1', nodes=[1603]), Data(x=[1861, 3], edge_index=[2, 61453], y=[1], drug='Erlotinib', cell_line='22RV1', nodes=[1861]), Data(x=[1583, 3], edge_index=[2, 27507], y=[1], drug='Sepantronium bromide', cell_line='22RV1', nodes=[1583]), Data(x=[1841, 3], edge_index=[2, 56845], y=[1], drug='Cediranib', cell_line='22RV1', nodes=[1841]), Data(x=[1797, 3], edge_index=[2, 51305], y=[1], drug='Buparlisib', cell_line='22RV1', nodes=[1797]), Data(x=[1564, 3], edge_index=[2, 27076], y=[1], drug='YK-4-279', cell_line='22RV1', nodes=[1564]), Data(x=[1773, 3], edge_index=[2, 47351], y=[1], drug='AZD8186', cell_line='22RV1', nodes=[1773]), Data(x=[1675, 3], edge_index=[2, 31705], y=[1], drug='UMI-77', cell_line='22RV1', nodes=[1675]), Data(x=[1791, 3], edge_index=[2, 47639], y=[1], drug='Cytarabine', cell_line='22RV1', nodes=[1791]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='BPD-00008900', cell_line='22RV1', nodes=[1552]), Data(x=[1562, 3], edge_index=[2, 27364], y=[1], drug='MIM1', cell_line='22RV1', nodes=[1562]), Data(x=[1807, 3], edge_index=[2, 53929], y=[1], drug='Dactolisib', cell_line='22RV1', nodes=[1807]), Data(x=[1562, 3], edge_index=[2, 27032], y=[1], drug='NVP-ADW742', cell_line='22RV1', nodes=[1562]), Data(x=[1885, 3], edge_index=[2, 68399], y=[1], drug='Gefitinib', cell_line='22RV1', nodes=[1885]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='Telomerase Inhibitor IX', cell_line='22RV1', nodes=[1552]), Data(x=[1590, 3], edge_index=[2, 27846], y=[1], drug='GDC0810', cell_line='22RV1', nodes=[1590]), Data(x=[1651, 3], edge_index=[2, 30979], y=[1], drug='WEHI-539', cell_line='22RV1', nodes=[1651]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='BDP-00009066', cell_line='22RV1', nodes=[1552]), Data(x=[1718, 3], edge_index=[2, 38738], y=[1], drug='Epirubicin', cell_line='22RV1', nodes=[1718]), Data(x=[1843, 3], edge_index=[2, 53949], y=[1], drug='GSK2578215A', cell_line='22RV1', nodes=[1843]), Data(x=[1678, 3], edge_index=[2, 32410], y=[1], drug='I-BRD9', cell_line='22RV1', nodes=[1678]), Data(x=[1568, 3], edge_index=[2, 27438], y=[1], drug='P22077', cell_line='22RV1', nodes=[1568]), Data(x=[1639, 3], edge_index=[2, 29873], y=[1], drug='AZD6738', cell_line='22RV1', nodes=[1639]), Data(x=[1777, 3], edge_index=[2, 47183], y=[1], drug='AZD5363', cell_line='22RV1', nodes=[1777]), Data(x=[1619, 3], edge_index=[2, 30339], y=[1], drug='BMS-536924', cell_line='22RV1', nodes=[1619]), Data(x=[1582, 3], edge_index=[2, 28514], y=[1], drug='ABT737', cell_line='22RV1', nodes=[1582]), Data(x=[1588, 3], edge_index=[2, 27512], y=[1], drug='WIKI4', cell_line='22RV1', nodes=[1588]), Data(x=[1769, 3], edge_index=[2, 46719], y=[1], drug='Afuresertib', cell_line='22RV1', nodes=[1769]), Data(x=[1765, 3], edge_index=[2, 45221], y=[1], drug='Savolitinib', cell_line='22RV1', nodes=[1765]), Data(x=[1652, 3], edge_index=[2, 32338], y=[1], drug='Navitoclax', cell_line='22RV1', nodes=[1652]), Data(x=[1801, 3], edge_index=[2, 43975], y=[1], drug='Cyclophosphamide', cell_line='22RV1', nodes=[1801]), Data(x=[1573, 3], edge_index=[2, 27161], y=[1], drug='MIRA-1', cell_line='22RV1', nodes=[1573]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='Pyridostatin', cell_line='22RV1', nodes=[1552]), Data(x=[1897, 3], edge_index=[2, 64429], y=[1], drug='Temozolomide', cell_line='22RV1', nodes=[1897]), Data(x=[1707, 3], edge_index=[2, 35907], y=[1], drug='Vinorelbine', cell_line='22RV1', nodes=[1707]), Data(x=[1764, 3], edge_index=[2, 44188], y=[1], drug='Vinblastine', cell_line='22RV1', nodes=[1764]), Data(x=[1580, 3], edge_index=[2, 27668], y=[1], drug='Pevonedistat', cell_line='22RV1', nodes=[1580]), Data(x=[1851, 3], edge_index=[2, 57337], y=[1], drug='Foretinib', cell_line='22RV1', nodes=[1851]), Data(x=[1562, 3], edge_index=[2, 26998], y=[1], drug='BIBR-1532', cell_line='22RV1', nodes=[1562]), Data(x=[1774, 3], edge_index=[2, 46430], y=[1], drug='MK-8776', cell_line='22RV1', nodes=[1774]), Data(x=[1694, 3], edge_index=[2, 33132], y=[1], drug='Talazoparib', cell_line='22RV1', nodes=[1694]), Data(x=[1572, 3], edge_index=[2, 27908], y=[1], drug='AMG-319', cell_line='22RV1', nodes=[1572]), Data(x=[1585, 3], edge_index=[2, 27445], y=[1], drug='AZ6102', cell_line='22RV1', nodes=[1585]), Data(x=[1749, 3], edge_index=[2, 44235], y=[1], drug='VX-11e', cell_line='22RV1', nodes=[1749]), Data(x=[1590, 3], edge_index=[2, 27558], y=[1], drug='LJI308', cell_line='22RV1', nodes=[1590]), Data(x=[1767, 3], edge_index=[2, 45639], y=[1], drug='AT13148', cell_line='22RV1', nodes=[1767]), Data(x=[1828, 3], edge_index=[2, 56300], y=[1], drug='Rapamycin', cell_line='22RV1', nodes=[1828]), Data(x=[1635, 3], edge_index=[2, 29495], y=[1], drug='GSK591', cell_line='22RV1', nodes=[1635]), Data(x=[1649, 3], edge_index=[2, 30239], y=[1], drug='VE821', cell_line='22RV1', nodes=[1649]), Data(x=[1569, 3], edge_index=[2, 27833], y=[1], drug='GNE-317', cell_line='22RV1', nodes=[1569]), Data(x=[1863, 3], edge_index=[2, 62811], y=[1], drug='Crizotinib', cell_line='22RV1', nodes=[1863]), Data(x=[1652, 3], edge_index=[2, 30854], y=[1], drug='Entinostat', cell_line='22RV1', nodes=[1652]), Data(x=[1810, 3], edge_index=[2, 53010], y=[1], drug='Alisertib', cell_line='22RV1', nodes=[1810]), Data(x=[1678, 3], edge_index=[2, 34006], y=[1], drug='Fludarabine', cell_line='22RV1', nodes=[1678]), Data(x=[1767, 3], edge_index=[2, 43915], y=[1], drug='Mitoxantrone', cell_line='22RV1', nodes=[1767]), Data(x=[1679, 3], edge_index=[2, 31423], y=[1], drug='Niraparib', cell_line='22RV1', nodes=[1679]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='JAK1_8709', cell_line='22RV1', nodes=[1552]), Data(x=[1875, 3], edge_index=[2, 59097], y=[1], drug='Leflunomide', cell_line='22RV1', nodes=[1875]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='IRAK4_4710', cell_line='22RV1', nodes=[1552]), Data(x=[1648, 3], edge_index=[2, 31124], y=[1], drug='Entospletinib', cell_line='22RV1', nodes=[1648]), Data(x=[1830, 3], edge_index=[2, 54212], y=[1], drug='BMS-345541', cell_line='22RV1', nodes=[1830]), Data(x=[1682, 3], edge_index=[2, 34062], y=[1], drug='Podophyllotoxin bromide', cell_line='22RV1', nodes=[1682]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='Gallibiscoquinazole', cell_line='22RV1', nodes=[1552]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='Sinularin', cell_line='22RV1', nodes=[1552]), Data(x=[1664, 3], edge_index=[2, 31088], y=[1], drug='PCI-34051', cell_line='22RV1', nodes=[1664]), Data(x=[1767, 3], edge_index=[2, 44995], y=[1], drug='Carmustine', cell_line='22RV1', nodes=[1767]), Data(x=[1766, 3], edge_index=[2, 41986], y=[1], drug='Topotecan', cell_line='22RV1', nodes=[1766]), Data(x=[1568, 3], edge_index=[2, 27232], y=[1], drug='AGI-6780', cell_line='22RV1', nodes=[1568]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='VSP34_8731', cell_line='22RV1', nodes=[1552]), Data(x=[1590, 3], edge_index=[2, 27560], y=[1], drug='MN-64', cell_line='22RV1', nodes=[1590]), Data(x=[1570, 3], edge_index=[2, 27336], y=[1], drug='ML323', cell_line='22RV1', nodes=[1570]), Data(x=[1703, 3], edge_index=[2, 33763], y=[1], drug='XAV939', cell_line='22RV1', nodes=[1703]), Data(x=[1673, 3], edge_index=[2, 31749], y=[1], drug='PFI3', cell_line='22RV1', nodes=[1673]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='Zoledronate', cell_line='22RV1', nodes=[1552]), Data(x=[1572, 3], edge_index=[2, 27908], y=[1], drug='CZC24832', cell_line='22RV1', nodes=[1572]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='KRAS (G12C) Inhibitor-12', cell_line='22RV1', nodes=[1552]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='ERK_2440', cell_line='22RV1', nodes=[1552]), Data(x=[1563, 3], edge_index=[2, 27007], y=[1], drug='Acetalax', cell_line='22RV1', nodes=[1563]), Data(x=[1694, 3], edge_index=[2, 37228], y=[1], drug='LY2109761', cell_line='22RV1', nodes=[1694]), Data(x=[1680, 3], edge_index=[2, 34720], y=[1], drug='AZD1332', cell_line='22RV1', nodes=[1680]), Data(x=[1562, 3], edge_index=[2, 26998], y=[1], drug='Mirin', cell_line='22RV1', nodes=[1562]), Data(x=[1673, 3], edge_index=[2, 32303], y=[1], drug='OTX015', cell_line='22RV1', nodes=[1673]), Data(x=[1564, 3], edge_index=[2, 27094], y=[1], drug='Wnt-C59', cell_line='22RV1', nodes=[1564]), Data(x=[1618, 3], edge_index=[2, 28216], y=[1], drug='PRIMA-1MET', cell_line='22RV1', nodes=[1618]), Data(x=[1587, 3], edge_index=[2, 29125], y=[1], drug='PRT062607', cell_line='22RV1', nodes=[1587]), Data(x=[1774, 3], edge_index=[2, 47854], y=[1], drug='AZD5438', cell_line='22RV1', nodes=[1774]), Data(x=[1566, 3], edge_index=[2, 27666], y=[1], drug='Obatoclax Mesylate', cell_line='22RV1', nodes=[1566]), Data(x=[1788, 3], edge_index=[2, 48964], y=[1], drug='AZD2014', cell_line='22RV1', nodes=[1788]), Data(x=[1673, 3], edge_index=[2, 31693], y=[1], drug='OF-1', cell_line='22RV1', nodes=[1673]), Data(x=[1843, 3], edge_index=[2, 59131], y=[1], drug='Selumetinib', cell_line='22RV1', nodes=[1843]), Data(x=[1650, 3], edge_index=[2, 30080], y=[1], drug='WZ4003', cell_line='22RV1', nodes=[1650]), Data(x=[1636, 3], edge_index=[2, 29826], y=[1], drug='Teniposide', cell_line='22RV1', nodes=[1636]), Data(x=[1600, 3], edge_index=[2, 27974], y=[1], drug='Picolinici-acid', cell_line='22RV1', nodes=[1600]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='JAK_8517', cell_line='22RV1', nodes=[1552]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='Elephantin', cell_line='22RV1', nodes=[1552]), Data(x=[1851, 3], edge_index=[2, 57881], y=[1], drug='Ruxolitinib', cell_line='22RV1', nodes=[1851]), Data(x=[1662, 3], edge_index=[2, 31570], y=[1], drug='VE-822', cell_line='22RV1', nodes=[1662]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='ERK_6604', cell_line='22RV1', nodes=[1552]), Data(x=[1566, 3], edge_index=[2, 27352], y=[1], drug='IWP-2', cell_line='22RV1', nodes=[1566]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='PAK_5339', cell_line='22RV1', nodes=[1552]), Data(x=[1612, 3], edge_index=[2, 28184], y=[1], drug='RVX-208', cell_line='22RV1', nodes=[1612]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='TAF1_5496', cell_line='22RV1', nodes=[1552]), Data(x=[1789, 3], edge_index=[2, 48023], y=[1], drug='Dinaciclib', cell_line='22RV1', nodes=[1789]), Data(x=[1562, 3], edge_index=[2, 26998], y=[1], drug='Nelarabine', cell_line='22RV1', nodes=[1562]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='IGF1R_3801', cell_line='22RV1', nodes=[1552]), Data(x=[1656, 3], edge_index=[2, 30514], y=[1], drug='GSK343', cell_line='22RV1', nodes=[1656]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='CDK9_5576', cell_line='22RV1', nodes=[1552]), Data(x=[1647, 3], edge_index=[2, 30207], y=[1], drug='LCL161', cell_line='22RV1', nodes=[1647]), Data(x=[1614, 3], edge_index=[2, 28734], y=[1], drug='I-BET-762', cell_line='22RV1', nodes=[1614]), Data(x=[1604, 3], edge_index=[2, 28296], y=[1], drug='AZD5153', cell_line='22RV1', nodes=[1604]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='CDK9_5038', cell_line='22RV1', nodes=[1552]), Data(x=[1782, 3], edge_index=[2, 47016], y=[1], drug='AZD1208', cell_line='22RV1', nodes=[1782]), Data(x=[1601, 3], edge_index=[2, 28109], y=[1], drug='Dihydrorotenone', cell_line='22RV1', nodes=[1601]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='ULK1_4989', cell_line='22RV1', nodes=[1552]), Data(x=[1569, 3], edge_index=[2, 27897], y=[1], drug='Sabutoclax', cell_line='22RV1', nodes=[1569]), Data(x=[1575, 3], edge_index=[2, 27669], y=[1], drug='AZ960', cell_line='22RV1', nodes=[1575]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='IAP_5620', cell_line='22RV1', nodes=[1552]), Data(x=[1811, 3], edge_index=[2, 52487], y=[1], drug='Ibrutinib', cell_line='22RV1', nodes=[1811]), Data(x=[1620, 3], edge_index=[2, 30134], y=[1], drug='AZD5991', cell_line='22RV1', nodes=[1620]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='Eg5_9814', cell_line='22RV1', nodes=[1552]), Data(x=[1838, 3], edge_index=[2, 55004], y=[1], drug='Vincristine', cell_line='22RV1', nodes=[1838]), Data(x=[1656, 3], edge_index=[2, 29388], y=[1], drug='GSK2606414', cell_line='22RV1', nodes=[1656]), Data(x=[1645, 3], edge_index=[2, 30009], y=[1], drug='AZD5582', cell_line='22RV1', nodes=[1645]), Data(x=[1620, 3], edge_index=[2, 28292], y=[1], drug='Daporinad', cell_line='22RV1', nodes=[1620]), Data(x=[1781, 3], edge_index=[2, 48277], y=[1], drug='OSI-027', cell_line='22RV1', nodes=[1781]), Data(x=[1781, 3], edge_index=[2, 49151], y=[1], drug='AZD8055', cell_line='22RV1', nodes=[1781]), Data(x=[1730, 3], edge_index=[2, 38436], y=[1], drug='SB216763', cell_line='22RV1', nodes=[1730]), Data(x=[1845, 3], edge_index=[2, 58215], y=[1], drug='Axitinib', cell_line='22RV1', nodes=[1845]), Data(x=[1624, 3], edge_index=[2, 30066], y=[1], drug='RO-3306', cell_line='22RV1', nodes=[1624]), Data(x=[1851, 3], edge_index=[2, 57013], y=[1], drug='Tozasertib', cell_line='22RV1', nodes=[1851]), Data(x=[1755, 3], edge_index=[2, 43047], y=[1], drug='GSK269962A', cell_line='22RV1', nodes=[1755]), Data(x=[1777, 3], edge_index=[2, 48591], y=[1], drug='KU-55933', cell_line='22RV1', nodes=[1777]), Data(x=[1584, 3], edge_index=[2, 28378], y=[1], drug='PF-4708671', cell_line='22RV1', nodes=[1584]), Data(x=[1845, 3], edge_index=[2, 57849], y=[1], drug='AZD6482', cell_line='22RV1', nodes=[1845]), Data(x=[1736, 3], edge_index=[2, 39586], y=[1], drug='ZM447439', cell_line='22RV1', nodes=[1736]), Data(x=[1715, 3], edge_index=[2, 35385], y=[1], drug='JQ1', cell_line='22RV1', nodes=[1715]), Data(x=[1677, 3], edge_index=[2, 33551], y=[1], drug='NU7441', cell_line='22RV1', nodes=[1677]), Data(x=[1768, 3], edge_index=[2, 47044], y=[1], drug='SB505124', cell_line='22RV1', nodes=[1768]), Data(x=[1804, 3], edge_index=[2, 51246], y=[1], drug='Ribociclib', cell_line='22RV1', nodes=[1804]), Data(x=[1839, 3], edge_index=[2, 55159], y=[1], drug='Doramapimod', cell_line='22RV1', nodes=[1839]), Data(x=[1779, 3], edge_index=[2, 47235], y=[1], drug='BMS-754807', cell_line='22RV1', nodes=[1779]), Data(x=[1841, 3], edge_index=[2, 56409], y=[1], drug='BI-2536', cell_line='22RV1', nodes=[1841]), Data(x=[1679, 3], edge_index=[2, 35765], y=[1], drug='Cetuximab', cell_line='22RV1', nodes=[1679]), Data(x=[1952, 3], edge_index=[2, 92886], y=[1], drug='Doxorubicin', cell_line='22RV1', nodes=[1952]), Data(x=[1824, 3], edge_index=[2, 57044], y=[1], drug='Etoposide', cell_line='22RV1', nodes=[1824]), Data(x=[1695, 3], edge_index=[2, 36785], y=[1], drug='Bleomycin', cell_line='22RV1', nodes=[1695]), Data(x=[1622, 3], edge_index=[2, 29328], y=[1], drug='Bicalutamide', cell_line='22RV1', nodes=[1622]), Data(x=[1552, 3], edge_index=[2, 26848], y=[1], drug='Bleomycin (50 uM)', cell_line='22RV1', nodes=[1552]), Data(x=[1668, 3], edge_index=[2, 32574], y=[1], drug='Pemetrexed', cell_line='22RV1', nodes=[1668]), Data(x=[1560, 3], edge_index=[2, 27504], y=[1], drug='AICA Ribonucleotide', cell_line='22RV1', nodes=[1560])], tensor([[ 3.0813,  2.8036,  4.2273,  1.1330, -4.9235, -2.9419, -3.1426,  2.4789,\n",
      "          2.4331,  0.9730,  0.6419,  5.5682,  2.0779,  2.8962,  4.7319, -2.1316,\n",
      "          3.3068,  4.1672,  6.0079,  5.9709,  2.0602,  5.1539,  2.5627, -1.6904,\n",
      "         -2.7205,  2.0701,  1.4836,  2.8287,  2.9487,  3.6223,  1.0072,  1.9073,\n",
      "          5.2389,  3.9515,  3.0664,  4.9616,  0.8468,  6.0605, -2.6083,  3.2331,\n",
      "          3.7440,  3.2675,  3.9359,  3.5102, -2.7993,  3.3032, -4.7364,  2.5978,\n",
      "          2.8619,  5.8931,  3.3842,  3.7046, -2.9966,  1.9765,  0.5852,  2.6381,\n",
      "          3.5261,  2.0055,  3.8269,  3.7895,  4.5096, -2.8818,  2.4314,  4.0326,\n",
      "          0.4599,  6.0627,  4.3358,  1.6863, -1.5561,  5.7670,  5.2649,  6.0833,\n",
      "          3.1851,  2.5016,  2.7378,  3.7481,  4.5811,  1.4638,  3.2580,  3.9634,\n",
      "          5.8420,  6.0825,  2.8721,  6.8046, -3.4660, -4.4593,  1.5677,  2.3186,\n",
      "          5.9922,  3.6462,  2.4075,  6.0692,  2.7714,  3.5173,  4.9340,  2.3787,\n",
      "         -4.4748,  5.6716,  5.6552, -0.2469,  3.2822,  1.8505,  2.5906,  6.0047,\n",
      "         -0.2257,  3.3523,  4.4308,  5.5208,  4.5051,  5.0229,  2.3351, -0.4825,\n",
      "          2.9954,  3.9522,  5.4451,  5.8155, -0.7767,  3.9011,  2.7480,  5.8536,\n",
      "          4.5629,  4.8256,  5.7720,  3.7453,  4.3971,  2.6940,  1.5477, -0.9338,\n",
      "          5.5894,  3.4227,  4.6675,  2.9609,  3.9106,  3.2156,  1.7698,  3.4244,\n",
      "          1.4876, -0.5516,  4.7294,  3.4878,  4.0010,  0.2751,  6.0459,  2.8484,\n",
      "          3.1785,  6.0629,  4.0890,  2.7723,  3.6810,  0.8639,  4.2772,  4.2140,\n",
      "         -2.7803,  6.3877,  0.8161,  3.4611, -0.8571,  5.5258,  2.2018,  0.7630,\n",
      "         -3.6502,  5.0038,  1.5890,  1.1414, -1.0582,  3.8427,  6.2451,  5.0320,\n",
      "          3.8712, -3.6300, -2.0970,  3.3338,  2.2467, -3.2848,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,\n",
      "          6.6838, -2.5002,  0.2465,  1.9390,  3.6731,  4.0313,  1.4566,  8.2777]]))\n"
     ]
    }
   ],
   "source": [
    "print(train_datasets[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14facac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "/sybig/home/tmu/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type       | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | gnn_encoder  | GNNEncoder | 316 K  | train\n",
      "1 | projection   | Sequential | 131 K  | train\n",
      "2 | latent_basis | Sequential | 131 K  | train\n",
      "3 | S            | Linear     | 51.4 K | train\n",
      "4 | A            | Sequential | 51.5 K | train\n",
      "----------------------------------------------------\n",
      "682 K     Trainable params\n",
      "0         Non-trainable params\n",
      "682 K     Total params\n",
      "2.728     Total estimated model params size (MB)\n",
      "32        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/sybig/home/tmu/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      "Epoch 0:   0%|          | 0/67 [00:00<?, ?it/s] Type of batch: <class 'list'>\n",
      "Length of batch: 2\n",
      "Type of first element: <class 'list'>\n",
      "First element keys: ['nodes', 'ptr', 'cell_line', 'drug', 'y', 'x', 'edge_index', 'batch']\n",
      "<class 'list'>\n",
      "200\n",
      "tensor([[ 4.5958,  1.4500,  4.2829,  ..., -0.3595,  1.7398,  7.0242],\n",
      "        [ 4.9857,  3.5065,  4.8551,  ...,  5.8730,  2.7540,  7.4831],\n",
      "        [ 2.5521,  0.8855,  3.3202,  ...,  2.7703, -2.6321,  6.9303],\n",
      "        ...,\n",
      "        [ 3.8278,  1.7202,  3.7536,  ..., -0.7913,  2.5872,  6.7696],\n",
      "        [ 4.5319,  2.6819,  2.8412,  ...,  2.2491,  2.5580,  5.9608],\n",
      "        [ 5.8677,  3.8628,  4.8139,  ...,  3.2862,  5.2424,  7.8333]])\n",
      "torch.Size([8, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:320\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mtugda_mtl_gnn.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Call the closure to compute the loss and gradients\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43moptimizer_closure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Perform the actual optimization step\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:131\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@torch\u001b[39m.enable_grad()\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> ClosureResult:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:319\u001b[39m, in \u001b[36m_AutomaticOptimization._training_step\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m.trainer\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m training_step_output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.strategy.post_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:391\u001b[39m, in \u001b[36mStrategy.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtraining_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 175\u001b[39m, in \u001b[36mtugda_mtl_gnn.training_step\u001b[39m\u001b[34m(self, batch, batch_idx)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# batch is a PyG Data object, no need to unpack\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     loss, task_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.log(\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m, loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 145\u001b[39m, in \u001b[36mtugda_mtl_gnn.forward_pass\u001b[39m\u001b[34m(self, batch, batch_idx)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m graph \u001b[38;5;129;01min\u001b[39;00m cell_line_graphs:\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# GNN Encoder aufrufen\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     graph_emb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgnn_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: [1, output_dim]\u001b[39;00m\n\u001b[32m    146\u001b[39m     all_embeddings.append(graph_emb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mGNNEncoder.forward\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Block 2\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m x = F.relu(\u001b[38;5;28mself\u001b[39m.head_transform2(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch_geometric/nn/conv/gat_conv.py:366\u001b[39m, in \u001b[36mGATConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.concat:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/torch_geometric.nn.conv.gat_conv_GATConv_propagate_gcedxs1w.py:212\u001b[39m, in \u001b[36mpropagate\u001b[39m\u001b[34m(self, edge_index, x, alpha, size)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch_geometric/nn/conv/message_passing.py:594\u001b[39m, in \u001b[36mMessagePassing.aggregate\u001b[39m\u001b[34m(self, inputs, index, ptr, dim_size)\u001b[39m\n\u001b[32m    584\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[32m    585\u001b[39m \u001b[33;03m:math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[32m    586\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    592\u001b[39m \u001b[33;03mas specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[32m    593\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch_geometric/experimental.py:117\u001b[39m, in \u001b[36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[33m'\u001b[39m\u001b[33mdisable_dynamic_shapes\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch_geometric/nn/aggr/base.py:131\u001b[39m, in \u001b[36mAggregation.__call__\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch_geometric/nn/aggr/basic.py:22\u001b[39m, in \u001b[36mSumAggregation.forward\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     20\u001b[39m             ptr: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     21\u001b[39m             dim: \u001b[38;5;28mint\u001b[39m = -\u001b[32m2\u001b[39m) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch_geometric/nn/aggr/base.py:185\u001b[39m, in \u001b[36mAggregation.reduce\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[39m\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAggregation requires \u001b[39m\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to be specified\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/torch_geometric/utils/_scatter.py:75\u001b[39m, in \u001b[36mscatter\u001b[39m\u001b[34m(src, index, dim, dim_size, reduce)\u001b[39m\n\u001b[32m     74\u001b[39m     index = broadcast(index, src, dim)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m.scatter_add_(dim, index, src)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce == \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m model = tugda_mtl_gnn(net_params, X_train, y_train, X_test, y_test)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Training starten\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Testen\u001b[39;00m\n\u001b[32m     46\u001b[39m results = trainer.test(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/node/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "pcorr_list = []\n",
    "\n",
    "metrics_callback = MetricsCallback()\n",
    "\n",
    "for k in range(1, 4):  # 3-fold\n",
    "    \n",
    "    print(f\"\\n--- Fold {k} ---\")\n",
    "    \n",
    "    # Original-Daten laden\n",
    "    full_train_dataset = train_datasets[k - 1]\n",
    "    full_test_dataset = test_datasets[k - 1]\n",
    "\n",
    "    full_y_train = full_train_dataset.labels_df.values\n",
    "    full_y_test = full_test_dataset.labels_df.values\n",
    "\n",
    "    X_train = full_train_dataset\n",
    "    X_test = full_test_dataset\n",
    "    y_train = full_y_train\n",
    "    y_test = full_y_test\n",
    "\n",
    "    # Trainer erstellen\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=net_params['epochs'],\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        callbacks=[metrics_callback],\n",
    "        deterministic=True,\n",
    "        # reload_dataloaders_every_epoch=True\n",
    "    )\n",
    "\n",
    "    # Seeds setzen\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    pl.seed_everything(seed)\n",
    "\n",
    "    # Modell erstellen\n",
    "    model = tugda_mtl_gnn(net_params, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Training starten\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # Testen\n",
    "    results = trainer.test(model)\n",
    "\n",
    "    # Fehler pro Drug speichern\n",
    "    error_per_task = results[0]['test_task_losses_per_class']\n",
    "    error_mtl_nn_results = np.concatenate((\n",
    "        np.array(drug_list, ndmin=2).T,\n",
    "        np.array(error_per_task, ndmin=2).T\n",
    "    ), axis=1)\n",
    "\n",
    "    print(\"Error per task:\")\n",
    "    print(error_mtl_nn_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "node",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
